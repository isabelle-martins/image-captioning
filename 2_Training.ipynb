{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** The CNN encoder uses Resnet-50 architecture with the last fully connected layer replaced by a linear layer that will be the input to the RNN decoder. The RNN decoder uses an embedding layer, a LSTM layer and a linear layer, that is used to predict the probability distribution over the vocabulary for the next word in the sequence. \n",
    "Regarding the hidden size, I used the same number as used on paper \"Show and Tell: A neural Image Caption Generator\" . Embedding size is the same that was already set on notebook 1 - preliminaries. The paper used the double, but I did not want the training to take too long. The batch size was based on the course content, having in mind that higher batch sizes requires more computational resources . Vocab threshold set on google paper was 5, but as the last iteration with data loader on previous notebook was 4, I decided to go with this number.\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:**  The transform was left at its provided value. The transform correctly resize the image to the expected CNN image input size, convert it to a PyTorch tensor and normalize the image, what helps to learn faster and better.\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** Params was set as suggested previously: params = list(decoder.parameters()) + list(encoder.embed.parameters())  . I thnk it is a good choice as the goal here is to to fine-tune a pre-trained encoder by optimizing the decoder and the embedding layer.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** I choose Adam, as SGD was used on \"Show and Tell: A neural Image Caption Generator\" articlebut it is more suitable for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.88s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 39/414113 [00:00<41:11, 167.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.88s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 466/414113 [00:00<29:17, 235.34it/s]\u001b[A\n",
      "  0%|          | 906/414113 [00:00<20:57, 328.66it/s]\u001b[A\n",
      "  0%|          | 1353/414113 [00:00<15:06, 455.15it/s]\u001b[A\n",
      "  0%|          | 1792/414113 [00:00<11:02, 622.54it/s]\u001b[A\n",
      "  1%|          | 2230/414113 [00:00<08:11, 838.22it/s]\u001b[A\n",
      "  1%|          | 2673/414113 [00:00<06:11, 1107.55it/s]\u001b[A\n",
      "  1%|          | 3111/414113 [00:00<04:47, 1427.38it/s]\u001b[A\n",
      "  1%|          | 3557/414113 [00:01<03:48, 1792.96it/s]\u001b[A\n",
      "  1%|          | 3994/414113 [00:01<03:08, 2177.84it/s]\u001b[A\n",
      "  1%|          | 4440/414113 [00:01<02:39, 2572.18it/s]\u001b[A\n",
      "  1%|          | 4876/414113 [00:01<02:19, 2932.75it/s]\u001b[A\n",
      "  1%|▏         | 5330/414113 [00:01<02:04, 3280.65it/s]\u001b[A\n",
      "  1%|▏         | 5768/414113 [00:01<01:55, 3543.93it/s]\u001b[A\n",
      "  1%|▏         | 6207/414113 [00:01<01:48, 3761.30it/s]\u001b[A\n",
      "  2%|▏         | 6645/414113 [00:01<01:43, 3920.82it/s]\u001b[A\n",
      "  2%|▏         | 7084/414113 [00:01<01:40, 4049.94it/s]\u001b[A\n",
      "  2%|▏         | 7528/414113 [00:01<01:37, 4157.62it/s]\u001b[A\n",
      "  2%|▏         | 7971/414113 [00:02<01:35, 4235.21it/s]\u001b[A\n",
      "  2%|▏         | 8412/414113 [00:02<01:34, 4275.88it/s]\u001b[A\n",
      "  2%|▏         | 8852/414113 [00:02<01:34, 4292.19it/s]\u001b[A\n",
      "  2%|▏         | 9290/414113 [00:02<01:34, 4302.48it/s]\u001b[A\n",
      "  2%|▏         | 9727/414113 [00:02<01:33, 4317.62it/s]\u001b[A\n",
      "  2%|▏         | 10168/414113 [00:02<01:33, 4341.99it/s]\u001b[A\n",
      "  3%|▎         | 10614/414113 [00:02<01:32, 4374.98it/s]\u001b[A\n",
      "  3%|▎         | 11054/414113 [00:02<01:32, 4375.53it/s]\u001b[A\n",
      "  3%|▎         | 11501/414113 [00:02<01:31, 4402.32it/s]\u001b[A\n",
      "  3%|▎         | 11949/414113 [00:02<01:30, 4423.56it/s]\u001b[A\n",
      "  3%|▎         | 12393/414113 [00:03<01:31, 4413.57it/s]\u001b[A\n",
      "  3%|▎         | 12835/414113 [00:03<01:31, 4399.60it/s]\u001b[A\n",
      "  3%|▎         | 13278/414113 [00:03<01:30, 4406.02it/s]\u001b[A\n",
      "  3%|▎         | 13721/414113 [00:03<01:30, 4410.82it/s]\u001b[A\n",
      "  3%|▎         | 14163/414113 [00:03<01:30, 4397.42it/s]\u001b[A\n",
      "  4%|▎         | 14606/414113 [00:03<01:30, 4404.30it/s]\u001b[A\n",
      "  4%|▎         | 15057/414113 [00:03<01:30, 4432.78it/s]\u001b[A\n",
      "  4%|▎         | 15501/414113 [00:03<01:30, 4419.65it/s]\u001b[A\n",
      "  4%|▍         | 15949/414113 [00:03<01:29, 4435.32it/s]\u001b[A\n",
      "  4%|▍         | 16393/414113 [00:03<01:32, 4305.63it/s]\u001b[A\n",
      "  4%|▍         | 16834/414113 [00:04<01:31, 4334.98it/s]\u001b[A\n",
      "  4%|▍         | 17284/414113 [00:04<01:30, 4382.81it/s]\u001b[A\n",
      "  4%|▍         | 17725/414113 [00:04<01:30, 4389.65it/s]\u001b[A\n",
      "  4%|▍         | 18175/414113 [00:04<01:29, 4421.20it/s]\u001b[A\n",
      "  4%|▍         | 18629/414113 [00:04<01:28, 4454.02it/s]\u001b[A\n",
      "  5%|▍         | 19075/414113 [00:04<01:28, 4453.47it/s]\u001b[A\n",
      "  5%|▍         | 19525/414113 [00:04<01:28, 4466.74it/s]\u001b[A\n",
      "  5%|▍         | 19979/414113 [00:04<01:27, 4487.22it/s]\u001b[A\n",
      "  5%|▍         | 20429/414113 [00:04<01:27, 4489.65it/s]\u001b[A\n",
      "  5%|▌         | 20884/414113 [00:04<01:27, 4506.86it/s]\u001b[A\n",
      "  5%|▌         | 21341/414113 [00:05<01:26, 4523.05it/s]\u001b[A\n",
      "  5%|▌         | 21797/414113 [00:05<01:26, 4532.50it/s]\u001b[A\n",
      "  5%|▌         | 22251/414113 [00:05<01:26, 4514.12it/s]\u001b[A\n",
      "  5%|▌         | 22703/414113 [00:05<01:26, 4500.74it/s]\u001b[A\n",
      "  6%|▌         | 23154/414113 [00:05<01:26, 4499.33it/s]\u001b[A\n",
      "  6%|▌         | 23604/414113 [00:05<01:26, 4498.01it/s]\u001b[A\n",
      "  6%|▌         | 24054/414113 [00:05<01:26, 4494.59it/s]\u001b[A\n",
      "  6%|▌         | 24509/414113 [00:05<01:26, 4509.50it/s]\u001b[A\n",
      "  6%|▌         | 24961/414113 [00:05<01:26, 4511.82it/s]\u001b[A\n",
      "  6%|▌         | 25413/414113 [00:05<01:26, 4495.94it/s]\u001b[A\n",
      "  6%|▌         | 25863/414113 [00:06<01:26, 4489.86it/s]\u001b[A\n",
      "  6%|▋         | 26313/414113 [00:06<01:26, 4473.22it/s]\u001b[A\n",
      "  6%|▋         | 26761/414113 [00:06<01:27, 4434.79it/s]\u001b[A\n",
      "  7%|▋         | 27205/414113 [00:06<01:27, 4427.02it/s]\u001b[A\n",
      "  7%|▋         | 27650/414113 [00:06<01:27, 4433.64it/s]\u001b[A\n",
      "  7%|▋         | 28103/414113 [00:06<01:26, 4461.07it/s]\u001b[A\n",
      "  7%|▋         | 28559/414113 [00:06<01:25, 4489.91it/s]\u001b[A\n",
      "  7%|▋         | 29009/414113 [00:06<01:25, 4478.16it/s]\u001b[A\n",
      "  7%|▋         | 29457/414113 [00:06<01:26, 4442.78it/s]\u001b[A\n",
      "  7%|▋         | 29916/414113 [00:06<01:25, 4483.55it/s]\u001b[A\n",
      "  7%|▋         | 30365/414113 [00:07<01:25, 4464.38it/s]\u001b[A\n",
      "  7%|▋         | 30814/414113 [00:07<01:25, 4472.03it/s]\u001b[A\n",
      "  8%|▊         | 31262/414113 [00:07<01:26, 4434.70it/s]\u001b[A\n",
      "  8%|▊         | 31723/414113 [00:07<01:25, 4483.47it/s]\u001b[A\n",
      "  8%|▊         | 32172/414113 [00:07<01:25, 4441.41it/s]\u001b[A\n",
      "  8%|▊         | 32619/414113 [00:07<01:25, 4449.82it/s]\u001b[A\n",
      "  8%|▊         | 33065/414113 [00:07<01:27, 4368.47it/s]\u001b[A\n",
      "  8%|▊         | 33503/414113 [00:07<01:27, 4344.95it/s]\u001b[A\n",
      "  8%|▊         | 33938/414113 [00:07<01:27, 4329.59it/s]\u001b[A\n",
      "  8%|▊         | 34372/414113 [00:07<01:27, 4328.49it/s]\u001b[A\n",
      "  8%|▊         | 34806/414113 [00:08<01:27, 4327.13it/s]\u001b[A\n",
      "  9%|▊         | 35239/414113 [00:08<01:27, 4321.56it/s]\u001b[A\n",
      "  9%|▊         | 35672/414113 [00:08<01:28, 4266.22it/s]\u001b[A\n",
      "  9%|▊         | 36121/414113 [00:08<01:27, 4329.45it/s]\u001b[A\n",
      "  9%|▉         | 36555/414113 [00:08<01:27, 4330.55it/s]\u001b[A\n",
      "  9%|▉         | 37008/414113 [00:08<01:25, 4385.27it/s]\u001b[A\n",
      "  9%|▉         | 37447/414113 [00:08<01:27, 4291.74it/s]\u001b[A\n",
      "  9%|▉         | 37917/414113 [00:08<01:25, 4406.14it/s]\u001b[A\n",
      "  9%|▉         | 38359/414113 [00:08<01:25, 4384.29it/s]\u001b[A\n",
      "  9%|▉         | 38817/414113 [00:09<01:24, 4439.71it/s]\u001b[A\n",
      "  9%|▉         | 39262/414113 [00:09<01:24, 4420.44it/s]\u001b[A\n",
      " 10%|▉         | 39710/414113 [00:09<01:24, 4435.72it/s]\u001b[A\n",
      " 10%|▉         | 40154/414113 [00:09<01:28, 4243.12it/s]\u001b[A\n",
      " 10%|▉         | 40607/414113 [00:09<01:26, 4324.00it/s]\u001b[A\n",
      " 10%|▉         | 41051/414113 [00:09<01:25, 4356.68it/s]\u001b[A\n",
      " 10%|█         | 41498/414113 [00:09<01:24, 4388.12it/s]\u001b[A\n",
      " 10%|█         | 41938/414113 [00:09<01:25, 4365.09it/s]\u001b[A\n",
      " 10%|█         | 42382/414113 [00:09<01:24, 4386.72it/s]\u001b[A\n",
      " 10%|█         | 42822/414113 [00:09<01:25, 4349.35it/s]\u001b[A\n",
      " 10%|█         | 43266/414113 [00:10<01:24, 4374.91it/s]\u001b[A\n",
      " 11%|█         | 43711/414113 [00:10<01:24, 4396.80it/s]\u001b[A\n",
      " 11%|█         | 44151/414113 [00:10<01:24, 4385.84it/s]\u001b[A\n",
      " 11%|█         | 44590/414113 [00:10<01:25, 4328.81it/s]\u001b[A\n",
      " 11%|█         | 45030/414113 [00:10<01:24, 4349.22it/s]\u001b[A\n",
      " 11%|█         | 45467/414113 [00:10<01:24, 4355.18it/s]\u001b[A\n",
      " 11%|█         | 45905/414113 [00:10<01:24, 4362.58it/s]\u001b[A\n",
      " 11%|█         | 46365/414113 [00:10<01:23, 4429.09it/s]\u001b[A\n",
      " 11%|█▏        | 46812/414113 [00:10<01:22, 4439.29it/s]\u001b[A\n",
      " 11%|█▏        | 47270/414113 [00:10<01:21, 4478.20it/s]\u001b[A\n",
      " 12%|█▏        | 47719/414113 [00:11<01:21, 4479.63it/s]\u001b[A\n",
      " 12%|█▏        | 48176/414113 [00:11<01:21, 4505.92it/s]\u001b[A\n",
      " 12%|█▏        | 48627/414113 [00:11<01:21, 4482.03it/s]\u001b[A\n",
      " 12%|█▏        | 49076/414113 [00:11<01:21, 4463.46it/s]\u001b[A\n",
      " 12%|█▏        | 49524/414113 [00:11<01:21, 4466.97it/s]\u001b[A\n",
      " 12%|█▏        | 49979/414113 [00:11<01:21, 4490.56it/s]\u001b[A\n",
      " 12%|█▏        | 50429/414113 [00:11<01:20, 4492.34it/s]\u001b[A\n",
      " 12%|█▏        | 50879/414113 [00:11<01:20, 4487.76it/s]\u001b[A\n",
      " 12%|█▏        | 51328/414113 [00:11<01:21, 4441.87it/s]\u001b[A\n",
      " 13%|█▎        | 51784/414113 [00:11<01:20, 4476.26it/s]\u001b[A\n",
      " 13%|█▎        | 52235/414113 [00:12<01:20, 4485.05it/s]\u001b[A\n",
      " 13%|█▎        | 52684/414113 [00:12<01:20, 4482.17it/s]\u001b[A\n",
      " 13%|█▎        | 53133/414113 [00:12<01:20, 4474.12it/s]\u001b[A\n",
      " 13%|█▎        | 53581/414113 [00:12<01:20, 4473.19it/s]\u001b[A\n",
      " 13%|█▎        | 54041/414113 [00:12<01:19, 4508.28it/s]\u001b[A\n",
      " 13%|█▎        | 54492/414113 [00:12<01:19, 4506.92it/s]\u001b[A\n",
      " 13%|█▎        | 54945/414113 [00:12<01:19, 4510.71it/s]\u001b[A\n",
      " 13%|█▎        | 55397/414113 [00:12<01:19, 4506.28it/s]\u001b[A\n",
      " 13%|█▎        | 55848/414113 [00:12<01:20, 4461.94it/s]\u001b[A\n",
      " 14%|█▎        | 56295/414113 [00:12<01:20, 4454.57it/s]\u001b[A\n",
      " 14%|█▎        | 56741/414113 [00:13<01:20, 4447.35it/s]\u001b[A\n",
      " 14%|█▍        | 57189/414113 [00:13<01:20, 4455.20it/s]\u001b[A\n",
      " 14%|█▍        | 57635/414113 [00:13<01:20, 4455.96it/s]\u001b[A\n",
      " 14%|█▍        | 58096/414113 [00:13<01:19, 4500.22it/s]\u001b[A\n",
      " 14%|█▍        | 58547/414113 [00:13<01:19, 4482.35it/s]\u001b[A\n",
      " 14%|█▍        | 58996/414113 [00:13<01:19, 4470.50it/s]\u001b[A\n",
      " 14%|█▍        | 59451/414113 [00:13<01:18, 4492.98it/s]\u001b[A\n",
      " 14%|█▍        | 59909/414113 [00:13<01:18, 4516.84it/s]\u001b[A\n",
      " 15%|█▍        | 60361/414113 [00:13<01:18, 4503.86it/s]\u001b[A\n",
      " 15%|█▍        | 60819/414113 [00:13<01:18, 4524.80it/s]\u001b[A\n",
      " 15%|█▍        | 61278/414113 [00:14<01:17, 4543.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 61733/414113 [00:14<01:17, 4540.73it/s]\u001b[A\n",
      " 15%|█▌        | 62188/414113 [00:14<01:18, 4488.94it/s]\u001b[A\n",
      " 15%|█▌        | 62644/414113 [00:14<01:17, 4508.35it/s]\u001b[A\n",
      " 15%|█▌        | 63095/414113 [00:14<01:17, 4501.21it/s]\u001b[A\n",
      " 15%|█▌        | 63546/414113 [00:14<01:18, 4488.50it/s]\u001b[A\n",
      " 15%|█▌        | 63999/414113 [00:14<01:17, 4498.70it/s]\u001b[A\n",
      " 16%|█▌        | 64449/414113 [00:14<01:18, 4479.03it/s]\u001b[A\n",
      " 16%|█▌        | 64903/414113 [00:14<01:17, 4493.90it/s]\u001b[A\n",
      " 16%|█▌        | 65354/414113 [00:14<01:17, 4498.42it/s]\u001b[A\n",
      " 16%|█▌        | 65804/414113 [00:15<01:17, 4491.73it/s]\u001b[A\n",
      " 16%|█▌        | 66254/414113 [00:15<01:17, 4485.47it/s]\u001b[A\n",
      " 16%|█▌        | 66703/414113 [00:15<01:18, 4452.48it/s]\u001b[A\n",
      " 16%|█▌        | 67150/414113 [00:15<01:17, 4455.65it/s]\u001b[A\n",
      " 16%|█▋        | 67596/414113 [00:15<01:17, 4456.53it/s]\u001b[A\n",
      " 16%|█▋        | 68042/414113 [00:15<01:17, 4442.72it/s]\u001b[A\n",
      " 17%|█▋        | 68493/414113 [00:15<01:17, 4462.50it/s]\u001b[A\n",
      " 17%|█▋        | 68945/414113 [00:15<01:17, 4477.57it/s]\u001b[A\n",
      " 17%|█▋        | 69396/414113 [00:15<01:16, 4484.76it/s]\u001b[A\n",
      " 17%|█▋        | 69845/414113 [00:15<01:17, 4439.12it/s]\u001b[A\n",
      " 17%|█▋        | 70296/414113 [00:16<01:17, 4458.04it/s]\u001b[A\n",
      " 17%|█▋        | 70742/414113 [00:16<01:17, 4431.09it/s]\u001b[A\n",
      " 17%|█▋        | 71187/414113 [00:16<01:17, 4436.26it/s]\u001b[A\n",
      " 17%|█▋        | 71631/414113 [00:16<01:17, 4415.12it/s]\u001b[A\n",
      " 17%|█▋        | 72090/414113 [00:16<01:16, 4463.76it/s]\u001b[A\n",
      " 18%|█▊        | 72548/414113 [00:16<01:15, 4496.48it/s]\u001b[A\n",
      " 18%|█▊        | 73007/414113 [00:16<01:15, 4522.06it/s]\u001b[A\n",
      " 18%|█▊        | 73460/414113 [00:16<01:15, 4498.53it/s]\u001b[A\n",
      " 18%|█▊        | 73928/414113 [00:16<01:14, 4549.45it/s]\u001b[A\n",
      " 18%|█▊        | 74384/414113 [00:16<01:14, 4531.11it/s]\u001b[A\n",
      " 18%|█▊        | 74838/414113 [00:17<01:14, 4528.07it/s]\u001b[A\n",
      " 18%|█▊        | 75291/414113 [00:17<01:15, 4460.11it/s]\u001b[A\n",
      " 18%|█▊        | 75738/414113 [00:17<01:16, 4399.74it/s]\u001b[A\n",
      " 18%|█▊        | 76185/414113 [00:17<01:16, 4420.55it/s]\u001b[A\n",
      " 19%|█▊        | 76630/414113 [00:17<01:16, 4427.12it/s]\u001b[A\n",
      " 19%|█▊        | 77082/414113 [00:17<01:15, 4452.18it/s]\u001b[A\n",
      " 19%|█▊        | 77528/414113 [00:17<01:15, 4431.23it/s]\u001b[A\n",
      " 19%|█▉        | 77972/414113 [00:17<01:15, 4429.08it/s]\u001b[A\n",
      " 19%|█▉        | 78423/414113 [00:17<01:15, 4451.97it/s]\u001b[A\n",
      " 19%|█▉        | 78871/414113 [00:17<01:15, 4459.46it/s]\u001b[A\n",
      " 19%|█▉        | 79318/414113 [00:18<01:15, 4429.27it/s]\u001b[A\n",
      " 19%|█▉        | 79770/414113 [00:18<01:15, 4454.89it/s]\u001b[A\n",
      " 19%|█▉        | 80216/414113 [00:18<01:15, 4446.54it/s]\u001b[A\n",
      " 19%|█▉        | 80661/414113 [00:18<01:15, 4438.55it/s]\u001b[A\n",
      " 20%|█▉        | 81108/414113 [00:18<01:14, 4447.09it/s]\u001b[A\n",
      " 20%|█▉        | 81565/414113 [00:18<01:14, 4481.40it/s]\u001b[A\n",
      " 20%|█▉        | 82014/414113 [00:18<01:14, 4466.78it/s]\u001b[A\n",
      " 20%|█▉        | 82471/414113 [00:18<01:13, 4495.97it/s]\u001b[A\n",
      " 20%|██        | 82924/414113 [00:18<01:13, 4506.08it/s]\u001b[A\n",
      " 20%|██        | 83375/414113 [00:18<01:13, 4497.20it/s]\u001b[A\n",
      " 20%|██        | 83825/414113 [00:19<01:13, 4484.82it/s]\u001b[A\n",
      " 20%|██        | 84278/414113 [00:19<01:13, 4498.25it/s]\u001b[A\n",
      " 20%|██        | 84728/414113 [00:19<01:13, 4488.19it/s]\u001b[A\n",
      " 21%|██        | 85179/414113 [00:19<01:13, 4493.83it/s]\u001b[A\n",
      " 21%|██        | 85629/414113 [00:19<01:13, 4449.42it/s]\u001b[A\n",
      " 21%|██        | 86077/414113 [00:19<01:13, 4458.26it/s]\u001b[A\n",
      " 21%|██        | 86526/414113 [00:19<01:13, 4465.91it/s]\u001b[A\n",
      " 21%|██        | 86973/414113 [00:19<01:13, 4443.41it/s]\u001b[A\n",
      " 21%|██        | 87427/414113 [00:19<01:13, 4469.45it/s]\u001b[A\n",
      " 21%|██        | 87878/414113 [00:20<01:12, 4478.78it/s]\u001b[A\n",
      " 21%|██▏       | 88337/414113 [00:20<01:12, 4508.63it/s]\u001b[A\n",
      " 21%|██▏       | 88796/414113 [00:20<01:11, 4532.27it/s]\u001b[A\n",
      " 22%|██▏       | 89250/414113 [00:20<01:12, 4487.06it/s]\u001b[A\n",
      " 22%|██▏       | 89699/414113 [00:20<01:12, 4468.68it/s]\u001b[A\n",
      " 22%|██▏       | 90147/414113 [00:20<01:12, 4464.58it/s]\u001b[A\n",
      " 22%|██▏       | 90594/414113 [00:20<01:12, 4455.94it/s]\u001b[A\n",
      " 22%|██▏       | 91040/414113 [00:20<01:12, 4429.96it/s]\u001b[A\n",
      " 22%|██▏       | 91507/414113 [00:20<01:11, 4497.67it/s]\u001b[A\n",
      " 22%|██▏       | 91958/414113 [00:20<01:11, 4499.01it/s]\u001b[A\n",
      " 22%|██▏       | 92429/414113 [00:21<01:10, 4560.00it/s]\u001b[A\n",
      " 22%|██▏       | 92886/414113 [00:21<01:10, 4536.19it/s]\u001b[A\n",
      " 23%|██▎       | 93342/414113 [00:21<01:10, 4541.37it/s]\u001b[A\n",
      " 23%|██▎       | 93797/414113 [00:21<01:10, 4516.13it/s]\u001b[A\n",
      " 23%|██▎       | 94260/414113 [00:21<01:10, 4548.05it/s]\u001b[A\n",
      " 23%|██▎       | 94726/414113 [00:21<01:09, 4580.19it/s]\u001b[A\n",
      " 23%|██▎       | 95185/414113 [00:21<01:09, 4564.11it/s]\u001b[A\n",
      " 23%|██▎       | 95642/414113 [00:21<01:09, 4552.02it/s]\u001b[A\n",
      " 23%|██▎       | 96098/414113 [00:21<01:10, 4503.26it/s]\u001b[A\n",
      " 23%|██▎       | 96559/414113 [00:21<01:10, 4532.74it/s]\u001b[A\n",
      " 23%|██▎       | 97013/414113 [00:22<01:10, 4509.09it/s]\u001b[A\n",
      " 24%|██▎       | 97469/414113 [00:22<01:09, 4523.95it/s]\u001b[A\n",
      " 24%|██▎       | 97922/414113 [00:22<01:10, 4501.58it/s]\u001b[A\n",
      " 24%|██▍       | 98373/414113 [00:22<01:10, 4461.04it/s]\u001b[A\n",
      " 24%|██▍       | 98828/414113 [00:22<01:10, 4487.15it/s]\u001b[A\n",
      " 24%|██▍       | 99285/414113 [00:22<01:09, 4510.42it/s]\u001b[A\n",
      " 24%|██▍       | 99737/414113 [00:22<01:10, 4490.00it/s]\u001b[A\n",
      " 24%|██▍       | 100187/414113 [00:22<01:10, 4472.21it/s]\u001b[A\n",
      " 24%|██▍       | 100635/414113 [00:23<02:02, 2568.46it/s]\u001b[A\n",
      " 24%|██▍       | 101071/414113 [00:23<01:46, 2928.05it/s]\u001b[A\n",
      " 25%|██▍       | 101489/414113 [00:23<01:37, 3215.30it/s]\u001b[A\n",
      " 25%|██▍       | 101942/414113 [00:23<01:28, 3521.87it/s]\u001b[A\n",
      " 25%|██▍       | 102386/414113 [00:23<01:23, 3753.55it/s]\u001b[A\n",
      " 25%|██▍       | 102846/414113 [00:23<01:18, 3971.76it/s]\u001b[A\n",
      " 25%|██▍       | 103305/414113 [00:23<01:15, 4137.38it/s]\u001b[A\n",
      " 25%|██▌       | 103758/414113 [00:23<01:13, 4247.19it/s]\u001b[A\n",
      " 25%|██▌       | 104216/414113 [00:23<01:11, 4341.13it/s]\u001b[A\n",
      " 25%|██▌       | 104671/414113 [00:23<01:10, 4400.98it/s]\u001b[A\n",
      " 25%|██▌       | 105121/414113 [00:24<01:10, 4378.98it/s]\u001b[A\n",
      " 25%|██▌       | 105568/414113 [00:24<01:10, 4404.04it/s]\u001b[A\n",
      " 26%|██▌       | 106014/414113 [00:24<01:09, 4413.33it/s]\u001b[A\n",
      " 26%|██▌       | 106459/414113 [00:24<01:09, 4411.84it/s]\u001b[A\n",
      " 26%|██▌       | 106910/414113 [00:24<01:09, 4439.77it/s]\u001b[A\n",
      " 26%|██▌       | 107356/414113 [00:24<01:09, 4435.91it/s]\u001b[A\n",
      " 26%|██▌       | 107803/414113 [00:24<01:08, 4444.75it/s]\u001b[A\n",
      " 26%|██▌       | 108254/414113 [00:24<01:08, 4460.89it/s]\u001b[A\n",
      " 26%|██▋       | 108716/414113 [00:24<01:07, 4505.34it/s]\u001b[A\n",
      " 26%|██▋       | 109168/414113 [00:24<01:08, 4463.05it/s]\u001b[A\n",
      " 26%|██▋       | 109615/414113 [00:25<01:08, 4437.13it/s]\u001b[A\n",
      " 27%|██▋       | 110065/414113 [00:25<01:08, 4452.92it/s]\u001b[A\n",
      " 27%|██▋       | 110511/414113 [00:25<01:08, 4435.00it/s]\u001b[A\n",
      " 27%|██▋       | 110955/414113 [00:25<01:08, 4428.42it/s]\u001b[A\n",
      " 27%|██▋       | 111398/414113 [00:25<01:08, 4423.19it/s]\u001b[A\n",
      " 27%|██▋       | 111849/414113 [00:25<01:07, 4447.08it/s]\u001b[A\n",
      " 27%|██▋       | 112294/414113 [00:25<01:08, 4413.52it/s]\u001b[A\n",
      " 27%|██▋       | 112745/414113 [00:25<01:07, 4439.61it/s]\u001b[A\n",
      " 27%|██▋       | 113200/414113 [00:25<01:07, 4469.06it/s]\u001b[A\n",
      " 27%|██▋       | 113648/414113 [00:26<01:07, 4468.75it/s]\u001b[A\n",
      " 28%|██▊       | 114095/414113 [00:26<01:07, 4443.44it/s]\u001b[A\n",
      " 28%|██▊       | 114541/414113 [00:26<01:07, 4447.91it/s]\u001b[A\n",
      " 28%|██▊       | 114988/414113 [00:26<01:07, 4452.37it/s]\u001b[A\n",
      " 28%|██▊       | 115434/414113 [00:26<01:07, 4442.04it/s]\u001b[A\n",
      " 28%|██▊       | 115882/414113 [00:26<01:07, 4450.83it/s]\u001b[A\n",
      " 28%|██▊       | 116345/414113 [00:26<01:06, 4502.19it/s]\u001b[A\n",
      " 28%|██▊       | 116796/414113 [00:26<01:06, 4477.45it/s]\u001b[A\n",
      " 28%|██▊       | 117244/414113 [00:26<01:06, 4478.16it/s]\u001b[A\n",
      " 28%|██▊       | 117705/414113 [00:26<01:05, 4514.68it/s]\u001b[A\n",
      " 29%|██▊       | 118165/414113 [00:27<01:05, 4537.86it/s]\u001b[A\n",
      " 29%|██▊       | 118619/414113 [00:27<01:05, 4504.30it/s]\u001b[A\n",
      " 29%|██▉       | 119073/414113 [00:27<01:05, 4513.35it/s]\u001b[A\n",
      " 29%|██▉       | 119525/414113 [00:27<01:05, 4487.55it/s]\u001b[A\n",
      " 29%|██▉       | 119974/414113 [00:27<01:05, 4478.78it/s]\u001b[A\n",
      " 29%|██▉       | 120434/414113 [00:27<01:05, 4513.74it/s]\u001b[A\n",
      " 29%|██▉       | 120886/414113 [00:27<01:04, 4513.55it/s]\u001b[A\n",
      " 29%|██▉       | 121339/414113 [00:27<01:04, 4515.51it/s]\u001b[A\n",
      " 29%|██▉       | 121791/414113 [00:27<01:05, 4486.03it/s]\u001b[A\n",
      " 30%|██▉       | 122243/414113 [00:27<01:04, 4493.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 122702/414113 [00:28<01:04, 4518.47it/s]\u001b[A\n",
      " 30%|██▉       | 123154/414113 [00:28<01:04, 4492.67it/s]\u001b[A\n",
      " 30%|██▉       | 123604/414113 [00:28<01:04, 4494.18it/s]\u001b[A\n",
      " 30%|██▉       | 124058/414113 [00:28<01:04, 4507.80it/s]\u001b[A\n",
      " 30%|███       | 124509/414113 [00:28<01:04, 4507.35it/s]\u001b[A\n",
      " 30%|███       | 124967/414113 [00:28<01:03, 4527.32it/s]\u001b[A\n",
      " 30%|███       | 125425/414113 [00:28<01:03, 4541.66it/s]\u001b[A\n",
      " 30%|███       | 125880/414113 [00:28<01:04, 4483.80it/s]\u001b[A\n",
      " 31%|███       | 126337/414113 [00:28<01:03, 4508.08it/s]\u001b[A\n",
      " 31%|███       | 126801/414113 [00:28<01:03, 4546.10it/s]\u001b[A\n",
      " 31%|███       | 127256/414113 [00:29<01:03, 4534.77it/s]\u001b[A\n",
      " 31%|███       | 127710/414113 [00:29<01:05, 4405.49it/s]\u001b[A\n",
      " 31%|███       | 128162/414113 [00:29<01:04, 4438.62it/s]\u001b[A\n",
      " 31%|███       | 128608/414113 [00:29<01:04, 4444.31it/s]\u001b[A\n",
      " 31%|███       | 129063/414113 [00:29<01:03, 4474.69it/s]\u001b[A\n",
      " 31%|███▏      | 129519/414113 [00:29<01:03, 4497.32it/s]\u001b[A\n",
      " 31%|███▏      | 129981/414113 [00:29<01:02, 4532.55it/s]\u001b[A\n",
      " 31%|███▏      | 130437/414113 [00:29<01:02, 4538.06it/s]\u001b[A\n",
      " 32%|███▏      | 130893/414113 [00:29<01:02, 4543.24it/s]\u001b[A\n",
      " 32%|███▏      | 131348/414113 [00:29<01:02, 4544.17it/s]\u001b[A\n",
      " 32%|███▏      | 131805/414113 [00:30<01:02, 4549.88it/s]\u001b[A\n",
      " 32%|███▏      | 132261/414113 [00:30<01:01, 4546.45it/s]\u001b[A\n",
      " 32%|███▏      | 132716/414113 [00:30<01:02, 4520.19it/s]\u001b[A\n",
      " 32%|███▏      | 133169/414113 [00:30<01:02, 4505.40it/s]\u001b[A\n",
      " 32%|███▏      | 133624/414113 [00:30<01:02, 4518.09it/s]\u001b[A\n",
      " 32%|███▏      | 134076/414113 [00:30<01:02, 4455.34it/s]\u001b[A\n",
      " 32%|███▏      | 134522/414113 [00:30<01:03, 4436.88it/s]\u001b[A\n",
      " 33%|███▎      | 134982/414113 [00:30<01:02, 4481.85it/s]\u001b[A\n",
      " 33%|███▎      | 135439/414113 [00:30<01:01, 4506.61it/s]\u001b[A\n",
      " 33%|███▎      | 135910/414113 [00:30<01:00, 4563.19it/s]\u001b[A\n",
      " 33%|███▎      | 136371/414113 [00:31<01:00, 4574.42it/s]\u001b[A\n",
      " 33%|███▎      | 136829/414113 [00:31<01:00, 4548.20it/s]\u001b[A\n",
      " 33%|███▎      | 137285/414113 [00:31<01:00, 4541.18it/s]\u001b[A\n",
      " 33%|███▎      | 137740/414113 [00:31<01:01, 4522.93it/s]\u001b[A\n",
      " 33%|███▎      | 138201/414113 [00:31<01:00, 4545.31it/s]\u001b[A\n",
      " 33%|███▎      | 138657/414113 [00:31<01:00, 4547.61it/s]\u001b[A\n",
      " 34%|███▎      | 139113/414113 [00:31<01:00, 4550.15it/s]\u001b[A\n",
      " 34%|███▎      | 139569/414113 [00:31<01:00, 4532.94it/s]\u001b[A\n",
      " 34%|███▍      | 140023/414113 [00:31<01:05, 4188.78it/s]\u001b[A\n",
      " 34%|███▍      | 140477/414113 [00:31<01:03, 4286.07it/s]\u001b[A\n",
      " 34%|███▍      | 140916/414113 [00:32<01:03, 4316.13it/s]\u001b[A\n",
      " 34%|███▍      | 141353/414113 [00:32<01:02, 4331.81it/s]\u001b[A\n",
      " 34%|███▍      | 141793/414113 [00:32<01:02, 4350.27it/s]\u001b[A\n",
      " 34%|███▍      | 142238/414113 [00:32<01:02, 4379.37it/s]\u001b[A\n",
      " 34%|███▍      | 142691/414113 [00:32<01:01, 4420.43it/s]\u001b[A\n",
      " 35%|███▍      | 143147/414113 [00:32<01:00, 4458.34it/s]\u001b[A\n",
      " 35%|███▍      | 143604/414113 [00:32<01:00, 4490.20it/s]\u001b[A\n",
      " 35%|███▍      | 144054/414113 [00:32<01:00, 4475.03it/s]\u001b[A\n",
      " 35%|███▍      | 144510/414113 [00:32<00:59, 4500.14it/s]\u001b[A\n",
      " 35%|███▌      | 144961/414113 [00:32<01:00, 4484.15it/s]\u001b[A\n",
      " 35%|███▌      | 145412/414113 [00:33<00:59, 4488.92it/s]\u001b[A\n",
      " 35%|███▌      | 145866/414113 [00:33<00:59, 4502.73it/s]\u001b[A\n",
      " 35%|███▌      | 146317/414113 [00:33<00:59, 4468.51it/s]\u001b[A\n",
      " 35%|███▌      | 146773/414113 [00:33<00:59, 4493.90it/s]\u001b[A\n",
      " 36%|███▌      | 147226/414113 [00:33<00:59, 4502.55it/s]\u001b[A\n",
      " 36%|███▌      | 147677/414113 [00:33<01:02, 4239.47it/s]\u001b[A\n",
      " 36%|███▌      | 148140/414113 [00:33<01:01, 4347.86it/s]\u001b[A\n",
      " 36%|███▌      | 148601/414113 [00:33<01:00, 4421.34it/s]\u001b[A\n",
      " 36%|███▌      | 149046/414113 [00:33<00:59, 4428.04it/s]\u001b[A\n",
      " 36%|███▌      | 149516/414113 [00:34<00:58, 4505.74it/s]\u001b[A\n",
      " 36%|███▌      | 149969/414113 [00:34<00:58, 4481.73it/s]\u001b[A\n",
      " 36%|███▋      | 150419/414113 [00:34<00:59, 4469.30it/s]\u001b[A\n",
      " 36%|███▋      | 150867/414113 [00:34<00:58, 4466.64it/s]\u001b[A\n",
      " 37%|███▋      | 151319/414113 [00:34<00:58, 4481.43it/s]\u001b[A\n",
      " 37%|███▋      | 151774/414113 [00:34<00:58, 4499.72it/s]\u001b[A\n",
      " 37%|███▋      | 152232/414113 [00:34<00:57, 4521.42it/s]\u001b[A\n",
      " 37%|███▋      | 152687/414113 [00:34<00:57, 4528.70it/s]\u001b[A\n",
      " 37%|███▋      | 153150/414113 [00:34<00:57, 4555.64it/s]\u001b[A\n",
      " 37%|███▋      | 153620/414113 [00:34<00:56, 4595.74it/s]\u001b[A\n",
      " 37%|███▋      | 154092/414113 [00:35<00:56, 4632.14it/s]\u001b[A\n",
      " 37%|███▋      | 154556/414113 [00:35<00:56, 4611.64it/s]\u001b[A\n",
      " 37%|███▋      | 155018/414113 [00:35<00:57, 4543.37it/s]\u001b[A\n",
      " 38%|███▊      | 155473/414113 [00:35<00:57, 4501.16it/s]\u001b[A\n",
      " 38%|███▊      | 155927/414113 [00:35<00:57, 4511.46it/s]\u001b[A\n",
      " 38%|███▊      | 156392/414113 [00:35<00:56, 4548.71it/s]\u001b[A\n",
      " 38%|███▊      | 156868/414113 [00:35<00:55, 4609.32it/s]\u001b[A\n",
      " 38%|███▊      | 157338/414113 [00:35<00:55, 4633.39it/s]\u001b[A\n",
      " 38%|███▊      | 157802/414113 [00:35<00:55, 4617.06it/s]\u001b[A\n",
      " 38%|███▊      | 158277/414113 [00:35<00:54, 4653.28it/s]\u001b[A\n",
      " 38%|███▊      | 158743/414113 [00:36<00:55, 4617.26it/s]\u001b[A\n",
      " 38%|███▊      | 159205/414113 [00:36<00:55, 4583.20it/s]\u001b[A\n",
      " 39%|███▊      | 159664/414113 [00:36<00:55, 4556.25it/s]\u001b[A\n",
      " 39%|███▊      | 160120/414113 [00:36<00:55, 4544.47it/s]\u001b[A\n",
      " 39%|███▉      | 160578/414113 [00:36<00:55, 4554.46it/s]\u001b[A\n",
      " 39%|███▉      | 161038/414113 [00:36<00:55, 4567.07it/s]\u001b[A\n",
      " 39%|███▉      | 161495/414113 [00:36<00:55, 4557.28it/s]\u001b[A\n",
      " 39%|███▉      | 161951/414113 [00:36<00:55, 4545.99it/s]\u001b[A\n",
      " 39%|███▉      | 162426/414113 [00:36<00:54, 4603.81it/s]\u001b[A\n",
      " 39%|███▉      | 162887/414113 [00:36<00:54, 4583.73it/s]\u001b[A\n",
      " 39%|███▉      | 163355/414113 [00:37<00:54, 4609.55it/s]\u001b[A\n",
      " 40%|███▉      | 163817/414113 [00:37<00:54, 4582.00it/s]\u001b[A\n",
      " 40%|███▉      | 164276/414113 [00:37<00:55, 4530.37it/s]\u001b[A\n",
      " 40%|███▉      | 164730/414113 [00:37<00:55, 4517.84it/s]\u001b[A\n",
      " 40%|███▉      | 165182/414113 [00:37<00:55, 4512.87it/s]\u001b[A\n",
      " 40%|███▉      | 165634/414113 [00:37<00:55, 4445.96it/s]\u001b[A\n",
      " 40%|████      | 166079/414113 [00:37<00:56, 4424.11it/s]\u001b[A\n",
      " 40%|████      | 166522/414113 [00:37<00:56, 4388.50it/s]\u001b[A\n",
      " 40%|████      | 166967/414113 [00:37<00:56, 4404.13it/s]\u001b[A\n",
      " 40%|████      | 167412/414113 [00:37<00:55, 4416.34it/s]\u001b[A\n",
      " 41%|████      | 167874/414113 [00:38<00:55, 4474.63it/s]\u001b[A\n",
      " 41%|████      | 168322/414113 [00:38<00:54, 4469.56it/s]\u001b[A\n",
      " 41%|████      | 168770/414113 [00:38<00:55, 4441.64it/s]\u001b[A\n",
      " 41%|████      | 169215/414113 [00:38<00:55, 4427.76it/s]\u001b[A\n",
      " 41%|████      | 169662/414113 [00:38<00:55, 4438.85it/s]\u001b[A\n",
      " 41%|████      | 170115/414113 [00:38<00:54, 4462.85it/s]\u001b[A\n",
      " 41%|████      | 170562/414113 [00:38<00:56, 4279.75it/s]\u001b[A\n",
      " 41%|████▏     | 171010/414113 [00:38<00:56, 4337.90it/s]\u001b[A\n",
      " 41%|████▏     | 171459/414113 [00:38<00:55, 4382.30it/s]\u001b[A\n",
      " 42%|████▏     | 171919/414113 [00:38<00:54, 4444.98it/s]\u001b[A\n",
      " 42%|████▏     | 172365/414113 [00:39<00:54, 4439.03it/s]\u001b[A\n",
      " 42%|████▏     | 172811/414113 [00:39<00:54, 4444.98it/s]\u001b[A\n",
      " 42%|████▏     | 173256/414113 [00:39<00:54, 4423.02it/s]\u001b[A\n",
      " 42%|████▏     | 173699/414113 [00:39<00:54, 4409.34it/s]\u001b[A\n",
      " 42%|████▏     | 174147/414113 [00:39<00:54, 4427.45it/s]\u001b[A\n",
      " 42%|████▏     | 174590/414113 [00:39<00:54, 4423.92it/s]\u001b[A\n",
      " 42%|████▏     | 175033/414113 [00:39<00:54, 4409.08it/s]\u001b[A\n",
      " 42%|████▏     | 175475/414113 [00:39<00:54, 4400.73it/s]\u001b[A\n",
      " 42%|████▏     | 175923/414113 [00:39<00:53, 4423.08it/s]\u001b[A\n",
      " 43%|████▎     | 176371/414113 [00:39<00:53, 4437.74it/s]\u001b[A\n",
      " 43%|████▎     | 176815/414113 [00:40<00:53, 4408.41it/s]\u001b[A\n",
      " 43%|████▎     | 177262/414113 [00:40<00:53, 4424.54it/s]\u001b[A\n",
      " 43%|████▎     | 177705/414113 [00:40<00:53, 4419.05it/s]\u001b[A\n",
      " 43%|████▎     | 178147/414113 [00:40<00:53, 4408.68it/s]\u001b[A\n",
      " 43%|████▎     | 178591/414113 [00:40<00:53, 4416.80it/s]\u001b[A\n",
      " 43%|████▎     | 179038/414113 [00:40<00:53, 4430.22it/s]\u001b[A\n",
      " 43%|████▎     | 179482/414113 [00:40<00:53, 4415.44it/s]\u001b[A\n",
      " 43%|████▎     | 179931/414113 [00:40<00:52, 4434.99it/s]\u001b[A\n",
      " 44%|████▎     | 180381/414113 [00:40<00:52, 4452.02it/s]\u001b[A\n",
      " 44%|████▎     | 180846/414113 [00:40<00:51, 4507.82it/s]\u001b[A\n",
      " 44%|████▍     | 181301/414113 [00:41<00:51, 4518.99it/s]\u001b[A\n",
      " 44%|████▍     | 181754/414113 [00:41<00:51, 4492.21it/s]\u001b[A\n",
      " 44%|████▍     | 182211/414113 [00:41<00:51, 4513.81it/s]\u001b[A\n",
      " 44%|████▍     | 182663/414113 [00:41<00:51, 4482.92it/s]\u001b[A\n",
      " 44%|████▍     | 183112/414113 [00:41<00:51, 4481.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 183561/414113 [00:41<00:51, 4468.06it/s]\u001b[A\n",
      " 44%|████▍     | 184008/414113 [00:41<00:51, 4455.96it/s]\u001b[A\n",
      " 45%|████▍     | 184454/414113 [00:41<00:51, 4456.62it/s]\u001b[A\n",
      " 45%|████▍     | 184915/414113 [00:41<00:50, 4498.84it/s]\u001b[A\n",
      " 45%|████▍     | 185374/414113 [00:41<00:50, 4525.65it/s]\u001b[A\n",
      " 45%|████▍     | 185827/414113 [00:42<00:50, 4502.30it/s]\u001b[A\n",
      " 45%|████▍     | 186278/414113 [00:42<00:50, 4477.26it/s]\u001b[A\n",
      " 45%|████▌     | 186745/414113 [00:42<00:50, 4531.76it/s]\u001b[A\n",
      " 45%|████▌     | 187199/414113 [00:42<00:50, 4477.73it/s]\u001b[A\n",
      " 45%|████▌     | 187648/414113 [00:42<00:50, 4475.90it/s]\u001b[A\n",
      " 45%|████▌     | 188098/414113 [00:42<00:50, 4482.39it/s]\u001b[A\n",
      " 46%|████▌     | 188547/414113 [00:42<00:50, 4470.96it/s]\u001b[A\n",
      " 46%|████▌     | 188995/414113 [00:42<00:50, 4457.68it/s]\u001b[A\n",
      " 46%|████▌     | 189460/414113 [00:42<00:49, 4511.98it/s]\u001b[A\n",
      " 46%|████▌     | 189920/414113 [00:43<00:49, 4535.99it/s]\u001b[A\n",
      " 46%|████▌     | 190374/414113 [00:43<00:49, 4523.60it/s]\u001b[A\n",
      " 46%|████▌     | 190827/414113 [00:43<00:49, 4516.00it/s]\u001b[A\n",
      " 46%|████▌     | 191279/414113 [00:43<00:49, 4502.44it/s]\u001b[A\n",
      " 46%|████▋     | 191730/414113 [00:43<00:49, 4473.76it/s]\u001b[A\n",
      " 46%|████▋     | 192178/414113 [00:43<00:50, 4414.10it/s]\u001b[A\n",
      " 47%|████▋     | 192631/414113 [00:43<00:49, 4447.57it/s]\u001b[A\n",
      " 47%|████▋     | 193076/414113 [00:43<00:49, 4426.72it/s]\u001b[A\n",
      " 47%|████▋     | 193519/414113 [00:43<00:50, 4409.09it/s]\u001b[A\n",
      " 47%|████▋     | 193988/414113 [00:43<00:49, 4489.20it/s]\u001b[A\n",
      " 47%|████▋     | 194438/414113 [00:44<00:48, 4491.94it/s]\u001b[A\n",
      " 47%|████▋     | 194889/414113 [00:44<00:48, 4495.57it/s]\u001b[A\n",
      " 47%|████▋     | 195339/414113 [00:44<00:48, 4466.43it/s]\u001b[A\n",
      " 47%|████▋     | 195792/414113 [00:44<00:48, 4484.11it/s]\u001b[A\n",
      " 47%|████▋     | 196251/414113 [00:44<00:48, 4513.13it/s]\u001b[A\n",
      " 47%|████▋     | 196703/414113 [00:44<00:48, 4467.83it/s]\u001b[A\n",
      " 48%|████▊     | 197150/414113 [00:44<00:51, 4251.45it/s]\u001b[A\n",
      " 48%|████▊     | 197607/414113 [00:44<00:49, 4341.74it/s]\u001b[A\n",
      " 48%|████▊     | 198060/414113 [00:44<00:49, 4394.82it/s]\u001b[A\n",
      " 48%|████▊     | 198503/414113 [00:44<00:48, 4404.50it/s]\u001b[A\n",
      " 48%|████▊     | 198960/414113 [00:45<00:48, 4450.43it/s]\u001b[A\n",
      " 48%|████▊     | 199406/414113 [00:45<00:48, 4449.19it/s]\u001b[A\n",
      " 48%|████▊     | 199852/414113 [00:45<00:48, 4426.08it/s]\u001b[A\n",
      " 48%|████▊     | 200306/414113 [00:45<00:47, 4458.14it/s]\u001b[A\n",
      " 48%|████▊     | 200753/414113 [00:45<00:47, 4450.39it/s]\u001b[A\n",
      " 49%|████▊     | 201211/414113 [00:45<00:47, 4488.18it/s]\u001b[A\n",
      " 49%|████▊     | 201669/414113 [00:45<00:47, 4514.83it/s]\u001b[A\n",
      " 49%|████▉     | 202122/414113 [00:45<00:46, 4516.69it/s]\u001b[A\n",
      " 49%|████▉     | 202574/414113 [00:45<00:47, 4490.92it/s]\u001b[A\n",
      " 49%|████▉     | 203028/414113 [00:45<00:46, 4505.24it/s]\u001b[A\n",
      " 49%|████▉     | 203481/414113 [00:46<00:46, 4511.12it/s]\u001b[A\n",
      " 49%|████▉     | 203933/414113 [00:46<00:47, 4470.96it/s]\u001b[A\n",
      " 49%|████▉     | 204387/414113 [00:46<00:46, 4488.97it/s]\u001b[A\n",
      " 49%|████▉     | 204846/414113 [00:46<00:46, 4516.11it/s]\u001b[A\n",
      " 50%|████▉     | 205301/414113 [00:46<00:46, 4523.88it/s]\u001b[A\n",
      " 50%|████▉     | 205754/414113 [00:46<00:46, 4521.33it/s]\u001b[A\n",
      " 50%|████▉     | 206207/414113 [00:46<00:45, 4523.43it/s]\u001b[A\n",
      " 50%|████▉     | 206660/414113 [00:46<00:45, 4518.64it/s]\u001b[A\n",
      " 50%|█████     | 207112/414113 [00:46<00:45, 4517.92it/s]\u001b[A\n",
      " 50%|█████     | 207572/414113 [00:46<00:45, 4541.42it/s]\u001b[A\n",
      " 50%|█████     | 208027/414113 [00:47<00:45, 4541.22it/s]\u001b[A\n",
      " 50%|█████     | 208482/414113 [00:47<00:45, 4522.67it/s]\u001b[A\n",
      " 50%|█████     | 208935/414113 [00:47<00:45, 4505.51it/s]\u001b[A\n",
      " 51%|█████     | 209395/414113 [00:47<00:45, 4531.29it/s]\u001b[A\n",
      " 51%|█████     | 209860/414113 [00:47<00:44, 4563.93it/s]\u001b[A\n",
      " 51%|█████     | 210317/414113 [00:47<00:45, 4507.73it/s]\u001b[A\n",
      " 51%|█████     | 210769/414113 [00:47<00:45, 4491.14it/s]\u001b[A\n",
      " 51%|█████     | 211219/414113 [00:47<00:45, 4466.63it/s]\u001b[A\n",
      " 51%|█████     | 211668/414113 [00:47<00:45, 4471.54it/s]\u001b[A\n",
      " 51%|█████     | 212116/414113 [00:47<00:45, 4470.75it/s]\u001b[A\n",
      " 51%|█████▏    | 212566/414113 [00:48<00:44, 4479.12it/s]\u001b[A\n",
      " 51%|█████▏    | 213023/414113 [00:48<00:44, 4503.62it/s]\u001b[A\n",
      " 52%|█████▏    | 213478/414113 [00:48<00:44, 4514.90it/s]\u001b[A\n",
      " 52%|█████▏    | 213940/414113 [00:48<00:44, 4544.74it/s]\u001b[A\n",
      " 52%|█████▏    | 214398/414113 [00:48<00:43, 4554.48it/s]\u001b[A\n",
      " 52%|█████▏    | 214854/414113 [00:48<00:43, 4552.30it/s]\u001b[A\n",
      " 52%|█████▏    | 215310/414113 [00:48<00:43, 4522.98it/s]\u001b[A\n",
      " 52%|█████▏    | 215763/414113 [00:48<00:43, 4511.93it/s]\u001b[A\n",
      " 52%|█████▏    | 216224/414113 [00:48<00:43, 4538.84it/s]\u001b[A\n",
      " 52%|█████▏    | 216681/414113 [00:48<00:43, 4546.58it/s]\u001b[A\n",
      " 52%|█████▏    | 217136/414113 [00:49<00:43, 4495.12it/s]\u001b[A\n",
      " 53%|█████▎    | 217586/414113 [00:49<00:44, 4392.93it/s]\u001b[A\n",
      " 53%|█████▎    | 218039/414113 [00:49<00:44, 4433.09it/s]\u001b[A\n",
      " 53%|█████▎    | 218497/414113 [00:49<00:43, 4476.04it/s]\u001b[A\n",
      " 53%|█████▎    | 218956/414113 [00:49<00:43, 4508.80it/s]\u001b[A\n",
      " 53%|█████▎    | 219408/414113 [00:49<00:43, 4500.23it/s]\u001b[A\n",
      " 53%|█████▎    | 219859/414113 [00:49<00:43, 4495.16it/s]\u001b[A\n",
      " 53%|█████▎    | 220309/414113 [00:49<00:43, 4470.26it/s]\u001b[A\n",
      " 53%|█████▎    | 220758/414113 [00:49<00:43, 4475.98it/s]\u001b[A\n",
      " 53%|█████▎    | 221208/414113 [00:49<00:43, 4482.17it/s]\u001b[A\n",
      " 54%|█████▎    | 221657/414113 [00:50<00:42, 4483.84it/s]\u001b[A\n",
      " 54%|█████▎    | 222106/414113 [00:50<00:42, 4477.75it/s]\u001b[A\n",
      " 54%|█████▎    | 222559/414113 [00:50<00:42, 4492.19it/s]\u001b[A\n",
      " 54%|█████▍    | 223009/414113 [00:50<00:42, 4482.06it/s]\u001b[A\n",
      " 54%|█████▍    | 223458/414113 [00:50<00:42, 4481.07it/s]\u001b[A\n",
      " 54%|█████▍    | 223914/414113 [00:50<00:42, 4502.57it/s]\u001b[A\n",
      " 54%|█████▍    | 224365/414113 [00:50<00:42, 4493.23it/s]\u001b[A\n",
      " 54%|█████▍    | 224823/414113 [00:50<00:41, 4516.35it/s]\u001b[A\n",
      " 54%|█████▍    | 225277/414113 [00:50<00:41, 4523.22it/s]\u001b[A\n",
      " 55%|█████▍    | 225730/414113 [00:50<00:41, 4490.03it/s]\u001b[A\n",
      " 55%|█████▍    | 226180/414113 [00:51<01:18, 2409.22it/s]\u001b[A\n",
      " 55%|█████▍    | 226643/414113 [00:51<01:06, 2813.78it/s]\u001b[A\n",
      " 55%|█████▍    | 227105/414113 [00:51<00:58, 3186.56it/s]\u001b[A\n",
      " 55%|█████▍    | 227565/414113 [00:51<00:53, 3509.72it/s]\u001b[A\n",
      " 55%|█████▌    | 228034/414113 [00:51<00:49, 3795.50it/s]\u001b[A\n",
      " 55%|█████▌    | 228485/414113 [00:51<00:46, 3983.67it/s]\u001b[A\n",
      " 55%|█████▌    | 228933/414113 [00:51<00:44, 4120.44it/s]\u001b[A\n",
      " 55%|█████▌    | 229376/414113 [00:52<00:43, 4208.24it/s]\u001b[A\n",
      " 55%|█████▌    | 229828/414113 [00:52<00:42, 4294.86it/s]\u001b[A\n",
      " 56%|█████▌    | 230275/414113 [00:52<00:42, 4344.23it/s]\u001b[A\n",
      " 56%|█████▌    | 230721/414113 [00:52<00:42, 4363.39it/s]\u001b[A\n",
      " 56%|█████▌    | 231188/414113 [00:52<00:41, 4447.43it/s]\u001b[A\n",
      " 56%|█████▌    | 231644/414113 [00:52<00:40, 4479.76it/s]\u001b[A\n",
      " 56%|█████▌    | 232097/414113 [00:52<00:40, 4461.30it/s]\u001b[A\n",
      " 56%|█████▌    | 232547/414113 [00:52<00:40, 4471.82it/s]\u001b[A\n",
      " 56%|█████▋    | 232997/414113 [00:52<00:40, 4431.81it/s]\u001b[A\n",
      " 56%|█████▋    | 233451/414113 [00:52<00:40, 4463.09it/s]\u001b[A\n",
      " 56%|█████▋    | 233901/414113 [00:53<00:40, 4469.29it/s]\u001b[A\n",
      " 57%|█████▋    | 234352/414113 [00:53<00:40, 4479.85it/s]\u001b[A\n",
      " 57%|█████▋    | 234801/414113 [00:53<00:40, 4463.70it/s]\u001b[A\n",
      " 57%|█████▋    | 235249/414113 [00:53<00:40, 4466.36it/s]\u001b[A\n",
      " 57%|█████▋    | 235696/414113 [00:53<00:39, 4463.16it/s]\u001b[A\n",
      " 57%|█████▋    | 236143/414113 [00:53<00:39, 4462.98it/s]\u001b[A\n",
      " 57%|█████▋    | 236590/414113 [00:53<00:43, 4087.68it/s]\u001b[A\n",
      " 57%|█████▋    | 237037/414113 [00:53<00:42, 4194.43it/s]\u001b[A\n",
      " 57%|█████▋    | 237488/414113 [00:53<00:41, 4282.46it/s]\u001b[A\n",
      " 57%|█████▋    | 237941/414113 [00:54<00:40, 4351.30it/s]\u001b[A\n",
      " 58%|█████▊    | 238381/414113 [00:54<00:40, 4364.13it/s]\u001b[A\n",
      " 58%|█████▊    | 238820/414113 [00:54<00:40, 4366.57it/s]\u001b[A\n",
      " 58%|█████▊    | 239260/414113 [00:54<00:39, 4376.17it/s]\u001b[A\n",
      " 58%|█████▊    | 239710/414113 [00:54<00:39, 4410.92it/s]\u001b[A\n",
      " 58%|█████▊    | 240165/414113 [00:54<00:39, 4449.84it/s]\u001b[A\n",
      " 58%|█████▊    | 240613/414113 [00:54<00:38, 4455.44it/s]\u001b[A\n",
      " 58%|█████▊    | 241059/414113 [00:54<00:39, 4413.90it/s]\u001b[A\n",
      " 58%|█████▊    | 241501/414113 [00:54<00:39, 4390.03it/s]\u001b[A\n",
      " 58%|█████▊    | 241953/414113 [00:54<00:38, 4427.16it/s]\u001b[A\n",
      " 59%|█████▊    | 242409/414113 [00:55<00:38, 4463.18it/s]\u001b[A\n",
      " 59%|█████▊    | 242856/414113 [00:55<00:38, 4438.38it/s]\u001b[A\n",
      " 59%|█████▉    | 243301/414113 [00:55<00:41, 4111.41it/s]\u001b[A\n",
      " 59%|█████▉    | 243743/414113 [00:55<00:40, 4197.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 244205/414113 [00:55<00:39, 4315.21it/s]\u001b[A\n",
      " 59%|█████▉    | 244664/414113 [00:55<00:38, 4393.98it/s]\u001b[A\n",
      " 59%|█████▉    | 245119/414113 [00:55<00:38, 4438.94it/s]\u001b[A\n",
      " 59%|█████▉    | 245573/414113 [00:55<00:37, 4467.11it/s]\u001b[A\n",
      " 59%|█████▉    | 246024/414113 [00:55<00:37, 4479.21it/s]\u001b[A\n",
      " 60%|█████▉    | 246476/414113 [00:55<00:37, 4489.45it/s]\u001b[A\n",
      " 60%|█████▉    | 246926/414113 [00:56<00:37, 4488.52it/s]\u001b[A\n",
      " 60%|█████▉    | 247376/414113 [00:56<00:37, 4486.10it/s]\u001b[A\n",
      " 60%|█████▉    | 247825/414113 [00:56<00:37, 4464.60it/s]\u001b[A\n",
      " 60%|█████▉    | 248272/414113 [00:56<00:37, 4444.00it/s]\u001b[A\n",
      " 60%|██████    | 248730/414113 [00:56<00:36, 4483.35it/s]\u001b[A\n",
      " 60%|██████    | 249179/414113 [00:56<00:36, 4481.47it/s]\u001b[A\n",
      " 60%|██████    | 249631/414113 [00:56<00:36, 4492.20it/s]\u001b[A\n",
      " 60%|██████    | 250081/414113 [00:56<00:36, 4480.36it/s]\u001b[A\n",
      " 60%|██████    | 250530/414113 [00:56<00:36, 4479.68it/s]\u001b[A\n",
      " 61%|██████    | 250980/414113 [00:56<00:36, 4484.51it/s]\u001b[A\n",
      " 61%|██████    | 251429/414113 [00:57<00:36, 4469.87it/s]\u001b[A\n",
      " 61%|██████    | 251889/414113 [00:57<00:36, 4505.88it/s]\u001b[A\n",
      " 61%|██████    | 252344/414113 [00:57<00:35, 4518.83it/s]\u001b[A\n",
      " 61%|██████    | 252800/414113 [00:57<00:35, 4530.79it/s]\u001b[A\n",
      " 61%|██████    | 253266/414113 [00:57<00:35, 4565.48it/s]\u001b[A\n",
      " 61%|██████▏   | 253723/414113 [00:57<00:35, 4551.53it/s]\u001b[A\n",
      " 61%|██████▏   | 254179/414113 [00:57<00:35, 4520.94it/s]\u001b[A\n",
      " 61%|██████▏   | 254632/414113 [00:57<00:35, 4464.75it/s]\u001b[A\n",
      " 62%|██████▏   | 255086/414113 [00:57<00:35, 4486.25it/s]\u001b[A\n",
      " 62%|██████▏   | 255535/414113 [00:57<00:35, 4472.82it/s]\u001b[A\n",
      " 62%|██████▏   | 255998/414113 [00:58<00:34, 4517.80it/s]\u001b[A\n",
      " 62%|██████▏   | 256459/414113 [00:58<00:34, 4542.36it/s]\u001b[A\n",
      " 62%|██████▏   | 256914/414113 [00:58<00:34, 4510.63it/s]\u001b[A\n",
      " 62%|██████▏   | 257372/414113 [00:58<00:34, 4528.81it/s]\u001b[A\n",
      " 62%|██████▏   | 257827/414113 [00:58<00:34, 4533.86it/s]\u001b[A\n",
      " 62%|██████▏   | 258281/414113 [00:58<00:34, 4509.02it/s]\u001b[A\n",
      " 62%|██████▏   | 258733/414113 [00:58<00:34, 4495.89it/s]\u001b[A\n",
      " 63%|██████▎   | 259183/414113 [00:58<00:34, 4461.60it/s]\u001b[A\n",
      " 63%|██████▎   | 259641/414113 [00:58<00:34, 4494.26it/s]\u001b[A\n",
      " 63%|██████▎   | 260098/414113 [00:58<00:34, 4514.83it/s]\u001b[A\n",
      " 63%|██████▎   | 260566/414113 [00:59<00:33, 4562.63it/s]\u001b[A\n",
      " 63%|██████▎   | 261023/414113 [00:59<00:33, 4564.64it/s]\u001b[A\n",
      " 63%|██████▎   | 261480/414113 [00:59<00:33, 4529.93it/s]\u001b[A\n",
      " 63%|██████▎   | 261934/414113 [00:59<00:33, 4521.48it/s]\u001b[A\n",
      " 63%|██████▎   | 262387/414113 [00:59<00:33, 4511.62it/s]\u001b[A\n",
      " 63%|██████▎   | 262839/414113 [00:59<00:33, 4487.13it/s]\u001b[A\n",
      " 64%|██████▎   | 263288/414113 [00:59<00:33, 4476.88it/s]\u001b[A\n",
      " 64%|██████▎   | 263736/414113 [00:59<00:33, 4456.06it/s]\u001b[A\n",
      " 64%|██████▍   | 264182/414113 [00:59<00:33, 4434.08it/s]\u001b[A\n",
      " 64%|██████▍   | 264626/414113 [00:59<00:33, 4405.07it/s]\u001b[A\n",
      " 64%|██████▍   | 265067/414113 [01:00<00:34, 4363.75it/s]\u001b[A\n",
      " 64%|██████▍   | 265504/414113 [01:00<00:34, 4346.83it/s]\u001b[A\n",
      " 64%|██████▍   | 265939/414113 [01:00<00:34, 4319.57it/s]\u001b[A\n",
      " 64%|██████▍   | 266373/414113 [01:00<00:34, 4324.42it/s]\u001b[A\n",
      " 64%|██████▍   | 266828/414113 [01:00<00:33, 4387.13it/s]\u001b[A\n",
      " 65%|██████▍   | 267278/414113 [01:00<00:33, 4417.84it/s]\u001b[A\n",
      " 65%|██████▍   | 267721/414113 [01:00<00:33, 4409.11it/s]\u001b[A\n",
      " 65%|██████▍   | 268170/414113 [01:00<00:32, 4431.28it/s]\u001b[A\n",
      " 65%|██████▍   | 268633/414113 [01:00<00:32, 4488.04it/s]\u001b[A\n",
      " 65%|██████▍   | 269084/414113 [01:01<00:32, 4492.89it/s]\u001b[A\n",
      " 65%|██████▌   | 269534/414113 [01:01<00:32, 4491.79it/s]\u001b[A\n",
      " 65%|██████▌   | 269984/414113 [01:01<00:32, 4489.86it/s]\u001b[A\n",
      " 65%|██████▌   | 270436/414113 [01:01<00:31, 4498.64it/s]\u001b[A\n",
      " 65%|██████▌   | 270886/414113 [01:01<00:32, 4454.23it/s]\u001b[A\n",
      " 66%|██████▌   | 271341/414113 [01:01<00:31, 4482.02it/s]\u001b[A\n",
      " 66%|██████▌   | 271790/414113 [01:01<00:31, 4467.53it/s]\u001b[A\n",
      " 66%|██████▌   | 272237/414113 [01:01<00:31, 4446.01it/s]\u001b[A\n",
      " 66%|██████▌   | 272682/414113 [01:01<00:31, 4439.55it/s]\u001b[A\n",
      " 66%|██████▌   | 273132/414113 [01:01<00:31, 4456.52it/s]\u001b[A\n",
      " 66%|██████▌   | 273589/414113 [01:02<00:31, 4488.53it/s]\u001b[A\n",
      " 66%|██████▌   | 274038/414113 [01:02<00:31, 4483.38it/s]\u001b[A\n",
      " 66%|██████▋   | 274496/414113 [01:02<00:30, 4511.88it/s]\u001b[A\n",
      " 66%|██████▋   | 274948/414113 [01:02<00:30, 4494.84it/s]\u001b[A\n",
      " 67%|██████▋   | 275398/414113 [01:02<00:31, 4466.93it/s]\u001b[A\n",
      " 67%|██████▋   | 275859/414113 [01:02<00:30, 4507.75it/s]\u001b[A\n",
      " 67%|██████▋   | 276310/414113 [01:02<00:30, 4499.73it/s]\u001b[A\n",
      " 67%|██████▋   | 276761/414113 [01:02<00:30, 4492.85it/s]\u001b[A\n",
      " 67%|██████▋   | 277211/414113 [01:02<00:30, 4452.36it/s]\u001b[A\n",
      " 67%|██████▋   | 277664/414113 [01:02<00:30, 4471.53it/s]\u001b[A\n",
      " 67%|██████▋   | 278123/414113 [01:03<00:30, 4506.04it/s]\u001b[A\n",
      " 67%|██████▋   | 278574/414113 [01:03<00:30, 4472.45it/s]\u001b[A\n",
      " 67%|██████▋   | 279022/414113 [01:03<00:30, 4472.24it/s]\u001b[A\n",
      " 67%|██████▋   | 279471/414113 [01:03<00:30, 4477.53it/s]\u001b[A\n",
      " 68%|██████▊   | 279923/414113 [01:03<00:29, 4489.83it/s]\u001b[A\n",
      " 68%|██████▊   | 280373/414113 [01:03<00:30, 4449.55it/s]\u001b[A\n",
      " 68%|██████▊   | 280830/414113 [01:03<00:29, 4483.17it/s]\u001b[A\n",
      " 68%|██████▊   | 281279/414113 [01:03<00:29, 4472.96it/s]\u001b[A\n",
      " 68%|██████▊   | 281731/414113 [01:03<00:29, 4484.64it/s]\u001b[A\n",
      " 68%|██████▊   | 282198/414113 [01:03<00:29, 4535.94it/s]\u001b[A\n",
      " 68%|██████▊   | 282652/414113 [01:04<00:29, 4531.16it/s]\u001b[A\n",
      " 68%|██████▊   | 283107/414113 [01:04<00:28, 4535.03it/s]\u001b[A\n",
      " 68%|██████▊   | 283561/414113 [01:04<00:28, 4518.41it/s]\u001b[A\n",
      " 69%|██████▊   | 284013/414113 [01:04<00:28, 4508.37it/s]\u001b[A\n",
      " 69%|██████▊   | 284464/414113 [01:04<00:28, 4478.44it/s]\u001b[A\n",
      " 69%|██████▉   | 284912/414113 [01:04<00:29, 4446.43it/s]\u001b[A\n",
      " 69%|██████▉   | 285357/414113 [01:04<00:30, 4265.44it/s]\u001b[A\n",
      " 69%|██████▉   | 285807/414113 [01:04<00:29, 4331.21it/s]\u001b[A\n",
      " 69%|██████▉   | 286269/414113 [01:04<00:28, 4413.97it/s]\u001b[A\n",
      " 69%|██████▉   | 286719/414113 [01:04<00:28, 4439.27it/s]\u001b[A\n",
      " 69%|██████▉   | 287173/414113 [01:05<00:28, 4468.72it/s]\u001b[A\n",
      " 69%|██████▉   | 287625/414113 [01:05<00:28, 4481.20it/s]\u001b[A\n",
      " 70%|██████▉   | 288082/414113 [01:05<00:27, 4506.14it/s]\u001b[A\n",
      " 70%|██████▉   | 288535/414113 [01:05<00:27, 4513.10it/s]\u001b[A\n",
      " 70%|██████▉   | 288994/414113 [01:05<00:27, 4532.80it/s]\u001b[A\n",
      " 70%|██████▉   | 289464/414113 [01:05<00:27, 4580.70it/s]\u001b[A\n",
      " 70%|███████   | 289923/414113 [01:05<00:27, 4579.28it/s]\u001b[A\n",
      " 70%|███████   | 290382/414113 [01:05<00:27, 4570.65it/s]\u001b[A\n",
      " 70%|███████   | 290840/414113 [01:05<00:27, 4565.13it/s]\u001b[A\n",
      " 70%|███████   | 291305/414113 [01:05<00:26, 4589.52it/s]\u001b[A\n",
      " 70%|███████   | 291765/414113 [01:06<00:26, 4549.23it/s]\u001b[A\n",
      " 71%|███████   | 292221/414113 [01:06<00:26, 4527.00it/s]\u001b[A\n",
      " 71%|███████   | 292674/414113 [01:06<00:27, 4472.13it/s]\u001b[A\n",
      " 71%|███████   | 293122/414113 [01:06<00:27, 4445.07it/s]\u001b[A\n",
      " 71%|███████   | 293574/414113 [01:06<00:26, 4464.47it/s]\u001b[A\n",
      " 71%|███████   | 294030/414113 [01:06<00:26, 4489.85it/s]\u001b[A\n",
      " 71%|███████   | 294486/414113 [01:06<00:26, 4509.60it/s]\u001b[A\n",
      " 71%|███████   | 294938/414113 [01:06<00:26, 4493.45it/s]\u001b[A\n",
      " 71%|███████▏  | 295397/414113 [01:06<00:26, 4521.16it/s]\u001b[A\n",
      " 71%|███████▏  | 295855/414113 [01:06<00:26, 4538.33it/s]\u001b[A\n",
      " 72%|███████▏  | 296309/414113 [01:07<00:26, 4510.50it/s]\u001b[A\n",
      " 72%|███████▏  | 296761/414113 [01:07<00:26, 4506.29it/s]\u001b[A\n",
      " 72%|███████▏  | 297217/414113 [01:07<00:25, 4521.76it/s]\u001b[A\n",
      " 72%|███████▏  | 297670/414113 [01:07<00:26, 4453.17it/s]\u001b[A\n",
      " 72%|███████▏  | 298128/414113 [01:07<00:25, 4489.69it/s]\u001b[A\n",
      " 72%|███████▏  | 298578/414113 [01:07<00:25, 4489.30it/s]\u001b[A\n",
      " 72%|███████▏  | 299028/414113 [01:07<00:25, 4467.16it/s]\u001b[A\n",
      " 72%|███████▏  | 299475/414113 [01:07<00:25, 4463.95it/s]\u001b[A\n",
      " 72%|███████▏  | 299927/414113 [01:07<00:25, 4479.18it/s]\u001b[A\n",
      " 73%|███████▎  | 300384/414113 [01:07<00:25, 4504.91it/s]\u001b[A\n",
      " 73%|███████▎  | 300835/414113 [01:08<00:25, 4498.45it/s]\u001b[A\n",
      " 73%|███████▎  | 301285/414113 [01:08<00:25, 4456.03it/s]\u001b[A\n",
      " 73%|███████▎  | 301743/414113 [01:08<00:25, 4490.89it/s]\u001b[A\n",
      " 73%|███████▎  | 302193/414113 [01:08<00:24, 4478.04it/s]\u001b[A\n",
      " 73%|███████▎  | 302641/414113 [01:08<00:25, 4448.46it/s]\u001b[A\n",
      " 73%|███████▎  | 303086/414113 [01:08<00:25, 4434.94it/s]\u001b[A\n",
      " 73%|███████▎  | 303537/414113 [01:08<00:24, 4457.05it/s]\u001b[A\n",
      " 73%|███████▎  | 303983/414113 [01:08<00:24, 4407.98it/s]\u001b[A\n",
      " 74%|███████▎  | 304441/414113 [01:08<00:24, 4457.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 304888/414113 [01:08<00:24, 4456.92it/s]\u001b[A\n",
      " 74%|███████▎  | 305334/414113 [01:09<00:24, 4438.70it/s]\u001b[A\n",
      " 74%|███████▍  | 305788/414113 [01:09<00:24, 4466.73it/s]\u001b[A\n",
      " 74%|███████▍  | 306235/414113 [01:09<00:24, 4354.64it/s]\u001b[A\n",
      " 74%|███████▍  | 306680/414113 [01:09<00:24, 4381.85it/s]\u001b[A\n",
      " 74%|███████▍  | 307138/414113 [01:09<00:24, 4438.66it/s]\u001b[A\n",
      " 74%|███████▍  | 307583/414113 [01:09<00:24, 4406.11it/s]\u001b[A\n",
      " 74%|███████▍  | 308030/414113 [01:09<00:23, 4423.20it/s]\u001b[A\n",
      " 74%|███████▍  | 308481/414113 [01:09<00:23, 4447.29it/s]\u001b[A\n",
      " 75%|███████▍  | 308926/414113 [01:09<00:23, 4447.46it/s]\u001b[A\n",
      " 75%|███████▍  | 309374/414113 [01:10<00:23, 4454.95it/s]\u001b[A\n",
      " 75%|███████▍  | 309825/414113 [01:10<00:23, 4470.50it/s]\u001b[A\n",
      " 75%|███████▍  | 310284/414113 [01:10<00:23, 4505.14it/s]\u001b[A\n",
      " 75%|███████▌  | 310735/414113 [01:10<00:23, 4461.62it/s]\u001b[A\n",
      " 75%|███████▌  | 311185/414113 [01:10<00:23, 4470.85it/s]\u001b[A\n",
      " 75%|███████▌  | 311633/414113 [01:10<00:22, 4458.00it/s]\u001b[A\n",
      " 75%|███████▌  | 312082/414113 [01:10<00:22, 4466.88it/s]\u001b[A\n",
      " 75%|███████▌  | 312542/414113 [01:10<00:22, 4505.23it/s]\u001b[A\n",
      " 76%|███████▌  | 312998/414113 [01:10<00:22, 4521.11it/s]\u001b[A\n",
      " 76%|███████▌  | 313452/414113 [01:10<00:22, 4524.43it/s]\u001b[A\n",
      " 76%|███████▌  | 313910/414113 [01:11<00:22, 4540.18it/s]\u001b[A\n",
      " 76%|███████▌  | 314371/414113 [01:11<00:21, 4558.67it/s]\u001b[A\n",
      " 76%|███████▌  | 314830/414113 [01:11<00:21, 4567.55it/s]\u001b[A\n",
      " 76%|███████▌  | 315287/414113 [01:11<00:21, 4517.68it/s]\u001b[A\n",
      " 76%|███████▌  | 315755/414113 [01:11<00:21, 4563.71it/s]\u001b[A\n",
      " 76%|███████▋  | 316218/414113 [01:11<00:21, 4582.11it/s]\u001b[A\n",
      " 76%|███████▋  | 316677/414113 [01:11<00:21, 4569.30it/s]\u001b[A\n",
      " 77%|███████▋  | 317138/414113 [01:11<00:21, 4581.13it/s]\u001b[A\n",
      " 77%|███████▋  | 317603/414113 [01:11<00:20, 4599.60it/s]\u001b[A\n",
      " 77%|███████▋  | 318064/414113 [01:11<00:20, 4582.07it/s]\u001b[A\n",
      " 77%|███████▋  | 318528/414113 [01:12<00:20, 4597.51it/s]\u001b[A\n",
      " 77%|███████▋  | 318988/414113 [01:12<00:20, 4576.04it/s]\u001b[A\n",
      " 77%|███████▋  | 319446/414113 [01:12<00:20, 4564.67it/s]\u001b[A\n",
      " 77%|███████▋  | 319903/414113 [01:12<00:20, 4562.34it/s]\u001b[A\n",
      " 77%|███████▋  | 320370/414113 [01:12<00:20, 4593.89it/s]\u001b[A\n",
      " 77%|███████▋  | 320836/414113 [01:12<00:20, 4612.86it/s]\u001b[A\n",
      " 78%|███████▊  | 321302/414113 [01:12<00:20, 4625.24it/s]\u001b[A\n",
      " 78%|███████▊  | 321765/414113 [01:12<00:19, 4619.13it/s]\u001b[A\n",
      " 78%|███████▊  | 322227/414113 [01:12<00:21, 4333.93it/s]\u001b[A\n",
      " 78%|███████▊  | 322686/414113 [01:12<00:20, 4404.09it/s]\u001b[A\n",
      " 78%|███████▊  | 323157/414113 [01:13<00:20, 4490.07it/s]\u001b[A\n",
      " 78%|███████▊  | 323613/414113 [01:13<00:20, 4508.50it/s]\u001b[A\n",
      " 78%|███████▊  | 324066/414113 [01:13<00:20, 4469.24it/s]\u001b[A\n",
      " 78%|███████▊  | 324515/414113 [01:13<00:20, 4475.27it/s]\u001b[A\n",
      " 78%|███████▊  | 324964/414113 [01:13<00:19, 4477.83it/s]\u001b[A\n",
      " 79%|███████▊  | 325413/414113 [01:13<00:20, 4419.96it/s]\u001b[A\n",
      " 79%|███████▊  | 325865/414113 [01:13<00:19, 4446.97it/s]\u001b[A\n",
      " 79%|███████▉  | 326311/414113 [01:13<00:19, 4440.36it/s]\u001b[A\n",
      " 79%|███████▉  | 326757/414113 [01:13<00:19, 4445.26it/s]\u001b[A\n",
      " 79%|███████▉  | 327214/414113 [01:13<00:19, 4480.73it/s]\u001b[A\n",
      " 79%|███████▉  | 327663/414113 [01:14<00:19, 4476.35it/s]\u001b[A\n",
      " 79%|███████▉  | 328111/414113 [01:14<00:19, 4473.76it/s]\u001b[A\n",
      " 79%|███████▉  | 328559/414113 [01:14<00:19, 4438.74it/s]\u001b[A\n",
      " 79%|███████▉  | 329004/414113 [01:14<00:19, 4439.04it/s]\u001b[A\n",
      " 80%|███████▉  | 329455/414113 [01:14<00:18, 4458.11it/s]\u001b[A\n",
      " 80%|███████▉  | 329902/414113 [01:14<00:18, 4460.85it/s]\u001b[A\n",
      " 80%|███████▉  | 330351/414113 [01:14<00:18, 4467.00it/s]\u001b[A\n",
      " 80%|███████▉  | 330798/414113 [01:14<00:18, 4419.19it/s]\u001b[A\n",
      " 80%|███████▉  | 331241/414113 [01:14<00:18, 4375.17it/s]\u001b[A\n",
      " 80%|████████  | 331692/414113 [01:14<00:18, 4412.13it/s]\u001b[A\n",
      " 80%|████████  | 332144/414113 [01:15<00:18, 4442.54it/s]\u001b[A\n",
      " 80%|████████  | 332597/414113 [01:15<00:18, 4468.29it/s]\u001b[A\n",
      " 80%|████████  | 333045/414113 [01:15<00:18, 4470.92it/s]\u001b[A\n",
      " 81%|████████  | 333508/414113 [01:15<00:17, 4515.79it/s]\u001b[A\n",
      " 81%|████████  | 333960/414113 [01:15<00:17, 4506.55it/s]\u001b[A\n",
      " 81%|████████  | 334412/414113 [01:15<00:17, 4508.63it/s]\u001b[A\n",
      " 81%|████████  | 334866/414113 [01:15<00:17, 4514.94it/s]\u001b[A\n",
      " 81%|████████  | 335318/414113 [01:15<00:17, 4498.38it/s]\u001b[A\n",
      " 81%|████████  | 335768/414113 [01:15<00:17, 4442.75it/s]\u001b[A\n",
      " 81%|████████  | 336213/414113 [01:15<00:17, 4429.90it/s]\u001b[A\n",
      " 81%|████████▏ | 336657/414113 [01:16<00:17, 4389.08it/s]\u001b[A\n",
      " 81%|████████▏ | 337097/414113 [01:16<00:17, 4384.55it/s]\u001b[A\n",
      " 82%|████████▏ | 337536/414113 [01:16<00:17, 4340.05it/s]\u001b[A\n",
      " 82%|████████▏ | 337972/414113 [01:16<00:17, 4343.68it/s]\u001b[A\n",
      " 82%|████████▏ | 338412/414113 [01:16<00:17, 4357.85it/s]\u001b[A\n",
      " 82%|████████▏ | 338851/414113 [01:16<00:17, 4365.09it/s]\u001b[A\n",
      " 82%|████████▏ | 339303/414113 [01:16<00:16, 4407.95it/s]\u001b[A\n",
      " 82%|████████▏ | 339750/414113 [01:16<00:16, 4426.04it/s]\u001b[A\n",
      " 82%|████████▏ | 340193/414113 [01:16<00:16, 4416.29it/s]\u001b[A\n",
      " 82%|████████▏ | 340649/414113 [01:16<00:16, 4458.07it/s]\u001b[A\n",
      " 82%|████████▏ | 341098/414113 [01:17<00:16, 4465.19it/s]\u001b[A\n",
      " 82%|████████▏ | 341545/414113 [01:17<00:16, 4443.37it/s]\u001b[A\n",
      " 83%|████████▎ | 341991/414113 [01:17<00:16, 4446.44it/s]\u001b[A\n",
      " 83%|████████▎ | 342447/414113 [01:17<00:15, 4479.91it/s]\u001b[A\n",
      " 83%|████████▎ | 342896/414113 [01:17<00:16, 4447.97it/s]\u001b[A\n",
      " 83%|████████▎ | 343353/414113 [01:17<00:15, 4481.40it/s]\u001b[A\n",
      " 83%|████████▎ | 343802/414113 [01:17<00:15, 4471.59it/s]\u001b[A\n",
      " 83%|████████▎ | 344250/414113 [01:17<00:15, 4461.58it/s]\u001b[A\n",
      " 83%|████████▎ | 344697/414113 [01:17<00:15, 4433.40it/s]\u001b[A\n",
      " 83%|████████▎ | 345144/414113 [01:17<00:15, 4442.27it/s]\u001b[A\n",
      " 83%|████████▎ | 345594/414113 [01:18<00:15, 4458.82it/s]\u001b[A\n",
      " 84%|████████▎ | 346051/414113 [01:18<00:15, 4490.90it/s]\u001b[A\n",
      " 84%|████████▎ | 346504/414113 [01:18<00:15, 4500.42it/s]\u001b[A\n",
      " 84%|████████▍ | 346955/414113 [01:18<00:14, 4494.25it/s]\u001b[A\n",
      " 84%|████████▍ | 347405/414113 [01:18<00:15, 4445.10it/s]\u001b[A\n",
      " 84%|████████▍ | 347868/414113 [01:18<00:14, 4495.82it/s]\u001b[A\n",
      " 84%|████████▍ | 348318/414113 [01:18<00:14, 4454.10it/s]\u001b[A\n",
      " 84%|████████▍ | 348764/414113 [01:18<00:14, 4420.43it/s]\u001b[A\n",
      " 84%|████████▍ | 349221/414113 [01:18<00:14, 4462.69it/s]\u001b[A\n",
      " 84%|████████▍ | 349670/414113 [01:19<00:14, 4469.20it/s]\u001b[A\n",
      " 85%|████████▍ | 350118/414113 [01:19<00:14, 4464.08it/s]\u001b[A\n",
      " 85%|████████▍ | 350577/414113 [01:19<00:14, 4499.47it/s]\u001b[A\n",
      " 85%|████████▍ | 351028/414113 [01:19<00:14, 4456.49it/s]\u001b[A\n",
      " 85%|████████▍ | 351477/414113 [01:19<00:14, 4463.42it/s]\u001b[A\n",
      " 85%|████████▍ | 351935/414113 [01:19<00:13, 4495.34it/s]\u001b[A\n",
      " 85%|████████▌ | 352385/414113 [01:19<00:13, 4477.50it/s]\u001b[A\n",
      " 85%|████████▌ | 352833/414113 [01:19<00:13, 4442.38it/s]\u001b[A\n",
      " 85%|████████▌ | 353278/414113 [01:19<00:13, 4440.99it/s]\u001b[A\n",
      " 85%|████████▌ | 353729/414113 [01:19<00:13, 4459.90it/s]\u001b[A\n",
      " 86%|████████▌ | 354186/414113 [01:20<00:13, 4489.35it/s]\u001b[A\n",
      " 86%|████████▌ | 354636/414113 [01:20<00:13, 4488.22it/s]\u001b[A\n",
      " 86%|████████▌ | 355085/414113 [01:20<00:13, 4463.70it/s]\u001b[A\n",
      " 86%|████████▌ | 355532/414113 [01:20<00:13, 4433.70it/s]\u001b[A\n",
      " 86%|████████▌ | 355976/414113 [01:20<00:13, 4395.19it/s]\u001b[A\n",
      " 86%|████████▌ | 356420/414113 [01:20<00:13, 4404.84it/s]\u001b[A\n",
      " 86%|████████▌ | 356866/414113 [01:20<00:12, 4419.91it/s]\u001b[A\n",
      " 86%|████████▋ | 357309/414113 [01:20<00:12, 4397.36it/s]\u001b[A\n",
      " 86%|████████▋ | 357779/414113 [01:20<00:12, 4482.47it/s]\u001b[A\n",
      " 87%|████████▋ | 358228/414113 [01:20<00:12, 4462.76it/s]\u001b[A\n",
      " 87%|████████▋ | 358692/414113 [01:21<00:12, 4512.03it/s]\u001b[A\n",
      " 87%|████████▋ | 359166/414113 [01:21<00:12, 4575.66it/s]\u001b[A\n",
      " 87%|████████▋ | 359625/414113 [01:21<00:12, 4504.60it/s]\u001b[A\n",
      " 87%|████████▋ | 360077/414113 [01:21<00:13, 4115.05it/s]\u001b[A\n",
      " 87%|████████▋ | 360523/414113 [01:21<00:12, 4210.47it/s]\u001b[A\n",
      " 87%|████████▋ | 360986/414113 [01:21<00:12, 4326.32it/s]\u001b[A\n",
      " 87%|████████▋ | 361451/414113 [01:21<00:11, 4417.57it/s]\u001b[A\n",
      " 87%|████████▋ | 361897/414113 [01:21<00:11, 4425.60it/s]\u001b[A\n",
      " 87%|████████▋ | 362343/414113 [01:21<00:11, 4427.16it/s]\u001b[A\n",
      " 88%|████████▊ | 362788/414113 [01:21<00:11, 4431.42it/s]\u001b[A\n",
      " 88%|████████▊ | 363233/414113 [01:22<00:11, 4409.66it/s]\u001b[A\n",
      " 88%|████████▊ | 363686/414113 [01:22<00:11, 4444.43it/s]\u001b[A\n",
      " 88%|████████▊ | 364135/414113 [01:22<00:11, 4456.79it/s]\u001b[A\n",
      " 88%|████████▊ | 364590/414113 [01:22<00:11, 4482.41it/s]\u001b[A\n",
      " 88%|████████▊ | 365050/414113 [01:22<00:10, 4515.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 365511/414113 [01:22<00:10, 4542.27it/s]\u001b[A\n",
      " 88%|████████▊ | 365966/414113 [01:22<00:10, 4505.85it/s]\u001b[A\n",
      " 88%|████████▊ | 366420/414113 [01:22<00:10, 4514.57it/s]\u001b[A\n",
      " 89%|████████▊ | 366872/414113 [01:22<00:10, 4499.39it/s]\u001b[A\n",
      " 89%|████████▊ | 367323/414113 [01:22<00:10, 4495.93it/s]\u001b[A\n",
      " 89%|████████▉ | 367773/414113 [01:23<00:10, 4461.75it/s]\u001b[A\n",
      " 89%|████████▉ | 368220/414113 [01:23<00:10, 4416.49it/s]\u001b[A\n",
      " 89%|████████▉ | 368673/414113 [01:23<00:10, 4447.68it/s]\u001b[A\n",
      " 89%|████████▉ | 369118/414113 [01:23<00:10, 4395.37it/s]\u001b[A\n",
      " 89%|████████▉ | 369559/414113 [01:23<00:10, 4399.13it/s]\u001b[A\n",
      " 89%|████████▉ | 370003/414113 [01:23<00:10, 4408.87it/s]\u001b[A\n",
      " 89%|████████▉ | 370445/414113 [01:23<00:09, 4403.67it/s]\u001b[A\n",
      " 90%|████████▉ | 370892/414113 [01:23<00:09, 4422.44it/s]\u001b[A\n",
      " 90%|████████▉ | 371342/414113 [01:23<00:09, 4443.70it/s]\u001b[A\n",
      " 90%|████████▉ | 371787/414113 [01:23<00:09, 4424.30it/s]\u001b[A\n",
      " 90%|████████▉ | 372230/414113 [01:24<00:09, 4409.99it/s]\u001b[A\n",
      " 90%|████████▉ | 372672/414113 [01:24<00:09, 4399.32it/s]\u001b[A\n",
      " 90%|█████████ | 373112/414113 [01:24<00:09, 4372.33it/s]\u001b[A\n",
      " 90%|█████████ | 373561/414113 [01:24<00:09, 4406.68it/s]\u001b[A\n",
      " 90%|█████████ | 374002/414113 [01:24<00:09, 4397.08it/s]\u001b[A\n",
      " 90%|█████████ | 374461/414113 [01:24<00:08, 4450.04it/s]\u001b[A\n",
      " 91%|█████████ | 374907/414113 [01:24<00:08, 4451.09it/s]\u001b[A\n",
      " 91%|█████████ | 375353/414113 [01:24<00:08, 4450.45it/s]\u001b[A\n",
      " 91%|█████████ | 375808/414113 [01:24<00:08, 4477.48it/s]\u001b[A\n",
      " 91%|█████████ | 376275/414113 [01:24<00:08, 4530.99it/s]\u001b[A\n",
      " 91%|█████████ | 376729/414113 [01:25<00:08, 4517.59it/s]\u001b[A\n",
      " 91%|█████████ | 377181/414113 [01:25<00:08, 4400.16it/s]\u001b[A\n",
      " 91%|█████████ | 377632/414113 [01:25<00:08, 4430.31it/s]\u001b[A\n",
      " 91%|█████████▏| 378076/414113 [01:25<00:08, 4421.53it/s]\u001b[A\n",
      " 91%|█████████▏| 378530/414113 [01:25<00:07, 4453.76it/s]\u001b[A\n",
      " 92%|█████████▏| 378978/414113 [01:25<00:07, 4458.68it/s]\u001b[A\n",
      " 92%|█████████▏| 379432/414113 [01:25<00:07, 4481.32it/s]\u001b[A\n",
      " 92%|█████████▏| 379881/414113 [01:25<00:07, 4435.90it/s]\u001b[A\n",
      " 92%|█████████▏| 380325/414113 [01:25<00:07, 4408.35it/s]\u001b[A\n",
      " 92%|█████████▏| 380767/414113 [01:26<00:07, 4396.87it/s]\u001b[A\n",
      " 92%|█████████▏| 381207/414113 [01:26<00:07, 4378.05it/s]\u001b[A\n",
      " 92%|█████████▏| 381651/414113 [01:26<00:07, 4396.09it/s]\u001b[A\n",
      " 92%|█████████▏| 382100/414113 [01:26<00:07, 4422.97it/s]\u001b[A\n",
      " 92%|█████████▏| 382543/414113 [01:26<00:07, 4419.65it/s]\u001b[A\n",
      " 92%|█████████▏| 383006/414113 [01:26<00:06, 4478.35it/s]\u001b[A\n",
      " 93%|█████████▎| 383455/414113 [01:26<00:06, 4447.50it/s]\u001b[A\n",
      " 93%|█████████▎| 383900/414113 [01:26<00:06, 4420.87it/s]\u001b[A\n",
      " 93%|█████████▎| 384343/414113 [01:26<00:06, 4376.46it/s]\u001b[A\n",
      " 93%|█████████▎| 384796/414113 [01:26<00:06, 4420.24it/s]\u001b[A\n",
      " 93%|█████████▎| 385239/414113 [01:27<00:13, 2192.49it/s]\u001b[A\n",
      " 93%|█████████▎| 385696/414113 [01:27<00:10, 2597.69it/s]\u001b[A\n",
      " 93%|█████████▎| 386134/414113 [01:27<00:09, 2957.84it/s]\u001b[A\n",
      " 93%|█████████▎| 386575/414113 [01:27<00:08, 3280.91it/s]\u001b[A\n",
      " 93%|█████████▎| 387016/414113 [01:27<00:07, 3553.11it/s]\u001b[A\n",
      " 94%|█████████▎| 387450/414113 [01:27<00:07, 3756.53it/s]\u001b[A\n",
      " 94%|█████████▎| 387895/414113 [01:27<00:06, 3938.54it/s]\u001b[A\n",
      " 94%|█████████▍| 388334/414113 [01:28<00:06, 4062.31it/s]\u001b[A\n",
      " 94%|█████████▍| 388771/414113 [01:28<00:06, 4149.42it/s]\u001b[A\n",
      " 94%|█████████▍| 389222/414113 [01:28<00:05, 4249.98it/s]\u001b[A\n",
      " 94%|█████████▍| 389674/414113 [01:28<00:05, 4325.68it/s]\u001b[A\n",
      " 94%|█████████▍| 390118/414113 [01:28<00:05, 4357.14it/s]\u001b[A\n",
      " 94%|█████████▍| 390570/414113 [01:28<00:05, 4404.14it/s]\u001b[A\n",
      " 94%|█████████▍| 391016/414113 [01:28<00:05, 4387.50it/s]\u001b[A\n",
      " 95%|█████████▍| 391467/414113 [01:28<00:05, 4423.31it/s]\u001b[A\n",
      " 95%|█████████▍| 391919/414113 [01:28<00:04, 4450.63it/s]\u001b[A\n",
      " 95%|█████████▍| 392366/414113 [01:28<00:04, 4456.25it/s]\u001b[A\n",
      " 95%|█████████▍| 392813/414113 [01:29<00:04, 4434.94it/s]\u001b[A\n",
      " 95%|█████████▍| 393258/414113 [01:29<00:04, 4373.75it/s]\u001b[A\n",
      " 95%|█████████▌| 393697/414113 [01:29<00:04, 4324.78it/s]\u001b[A\n",
      " 95%|█████████▌| 394153/414113 [01:29<00:04, 4391.85it/s]\u001b[A\n",
      " 95%|█████████▌| 394599/414113 [01:29<00:04, 4410.50it/s]\u001b[A\n",
      " 95%|█████████▌| 395043/414113 [01:29<00:04, 4417.04it/s]\u001b[A\n",
      " 96%|█████████▌| 395486/414113 [01:29<00:04, 4409.42it/s]\u001b[A\n",
      " 96%|█████████▌| 395929/414113 [01:29<00:04, 4414.21it/s]\u001b[A\n",
      " 96%|█████████▌| 396374/414113 [01:29<00:04, 4423.36it/s]\u001b[A\n",
      " 96%|█████████▌| 396823/414113 [01:29<00:03, 4442.73it/s]\u001b[A\n",
      " 96%|█████████▌| 397271/414113 [01:30<00:03, 4451.86it/s]\u001b[A\n",
      " 96%|█████████▌| 397717/414113 [01:30<00:03, 4401.44it/s]\u001b[A\n",
      " 96%|█████████▌| 398163/414113 [01:30<00:03, 4417.47it/s]\u001b[A\n",
      " 96%|█████████▋| 398605/414113 [01:30<00:03, 4392.66it/s]\u001b[A\n",
      " 96%|█████████▋| 399048/414113 [01:30<00:03, 4401.04it/s]\u001b[A\n",
      " 96%|█████████▋| 399489/414113 [01:30<00:03, 4395.96it/s]\u001b[A\n",
      " 97%|█████████▋| 399934/414113 [01:30<00:03, 4410.25it/s]\u001b[A\n",
      " 97%|█████████▋| 400376/414113 [01:30<00:03, 4382.07it/s]\u001b[A\n",
      " 97%|█████████▋| 400816/414113 [01:30<00:03, 4385.85it/s]\u001b[A\n",
      " 97%|█████████▋| 401255/414113 [01:30<00:02, 4380.42it/s]\u001b[A\n",
      " 97%|█████████▋| 401699/414113 [01:31<00:02, 4394.44it/s]\u001b[A\n",
      " 97%|█████████▋| 402139/414113 [01:31<00:02, 4370.56it/s]\u001b[A\n",
      " 97%|█████████▋| 402577/414113 [01:31<00:02, 4361.58it/s]\u001b[A\n",
      " 97%|█████████▋| 403024/414113 [01:31<00:02, 4392.79it/s]\u001b[A\n",
      " 97%|█████████▋| 403464/414113 [01:31<00:02, 4385.32it/s]\u001b[A\n",
      " 98%|█████████▊| 403903/414113 [01:31<00:02, 4297.73it/s]\u001b[A\n",
      " 98%|█████████▊| 404355/414113 [01:31<00:02, 4360.18it/s]\u001b[A\n",
      " 98%|█████████▊| 404792/414113 [01:31<00:02, 4359.74it/s]\u001b[A\n",
      " 98%|█████████▊| 405231/414113 [01:31<00:02, 4366.05it/s]\u001b[A\n",
      " 98%|█████████▊| 405670/414113 [01:31<00:01, 4370.38it/s]\u001b[A\n",
      " 98%|█████████▊| 406108/414113 [01:32<00:01, 4354.22it/s]\u001b[A\n",
      " 98%|█████████▊| 406549/414113 [01:32<00:01, 4369.95it/s]\u001b[A\n",
      " 98%|█████████▊| 406987/414113 [01:32<00:01, 4372.39it/s]\u001b[A\n",
      " 98%|█████████▊| 407432/414113 [01:32<00:01, 4395.13it/s]\u001b[A\n",
      " 98%|█████████▊| 407880/414113 [01:32<00:01, 4418.59it/s]\u001b[A\n",
      " 99%|█████████▊| 408322/414113 [01:32<00:01, 4401.86it/s]\u001b[A\n",
      " 99%|█████████▊| 408770/414113 [01:32<00:01, 4423.65it/s]\u001b[A\n",
      " 99%|█████████▉| 409213/414113 [01:32<00:01, 4397.39it/s]\u001b[A\n",
      " 99%|█████████▉| 409660/414113 [01:32<00:01, 4417.09it/s]\u001b[A\n",
      " 99%|█████████▉| 410102/414113 [01:33<00:00, 4380.94it/s]\u001b[A\n",
      " 99%|█████████▉| 410551/414113 [01:33<00:00, 4411.95it/s]\u001b[A\n",
      " 99%|█████████▉| 410995/414113 [01:33<00:00, 4418.06it/s]\u001b[A\n",
      " 99%|█████████▉| 411437/414113 [01:33<00:00, 4400.43it/s]\u001b[A\n",
      " 99%|█████████▉| 411883/414113 [01:33<00:00, 4416.07it/s]\u001b[A\n",
      "100%|█████████▉| 412325/414113 [01:33<00:00, 4394.86it/s]\u001b[A\n",
      "100%|█████████▉| 412775/414113 [01:33<00:00, 4424.25it/s]\u001b[A\n",
      "100%|█████████▉| 413234/414113 [01:33<00:00, 4472.60it/s]\u001b[A\n",
      "100%|█████████▉| 413684/414113 [01:33<00:00, 4477.29it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:33<00:00, 4409.70it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1671168/102502400 [00:00<00:06, 16386719.81it/s]\u001b[A\n",
      "  3%|▎         | 3407872/102502400 [00:00<00:05, 16664034.70it/s]\u001b[A\n",
      "  5%|▍         | 5079040/102502400 [00:00<00:06, 16108143.25it/s]\u001b[A\n",
      "  7%|▋         | 6905856/102502400 [00:00<00:05, 16700371.65it/s]\u001b[A\n",
      "  8%|▊         | 8486912/102502400 [00:00<00:05, 15773531.17it/s]\u001b[A\n",
      " 10%|▉         | 10174464/102502400 [00:00<00:05, 16086787.77it/s]\u001b[A\n",
      " 12%|█▏        | 11894784/102502400 [00:00<00:05, 15808337.42it/s]\u001b[A\n",
      " 13%|█▎        | 13615104/102502400 [00:00<00:05, 16198355.02it/s]\u001b[A\n",
      " 15%|█▍        | 15302656/102502400 [00:00<00:05, 15810158.76it/s]\u001b[A\n",
      " 17%|█▋        | 17137664/102502400 [00:01<00:05, 15945641.55it/s]\u001b[A\n",
      " 19%|█▊        | 18972672/102502400 [00:01<00:05, 16060166.29it/s]\u001b[A\n",
      " 20%|██        | 20676608/102502400 [00:01<00:05, 16338542.33it/s]\u001b[A\n",
      " 22%|██▏       | 22380544/102502400 [00:01<00:05, 15995105.79it/s]\u001b[A\n",
      " 23%|██▎       | 23969792/102502400 [00:01<00:04, 15899446.88it/s]\u001b[A\n",
      " 25%|██▌       | 25632768/102502400 [00:01<00:04, 16090768.37it/s]\u001b[A\n",
      " 27%|██▋       | 27238400/102502400 [00:01<00:04, 15570199.86it/s]\u001b[A\n",
      " 28%|██▊       | 28803072/102502400 [00:01<00:04, 15029870.21it/s]\u001b[A\n",
      " 30%|██▉       | 30310400/102502400 [00:01<00:04, 14917635.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31924224/102502400 [00:02<00:04, 15261608.99it/s]\u001b[A\n",
      " 33%|███▎      | 33652736/102502400 [00:02<00:04, 15403417.87it/s]\u001b[A\n",
      " 35%|███▍      | 35389440/102502400 [00:02<00:04, 15940500.36it/s]\u001b[A\n",
      " 36%|███▌      | 36995072/102502400 [00:02<00:04, 15851888.82it/s]\u001b[A\n",
      " 38%|███▊      | 38633472/102502400 [00:02<00:04, 15566798.78it/s]\u001b[A\n",
      " 39%|███▉      | 40468480/102502400 [00:02<00:03, 15786845.29it/s]\u001b[A\n",
      " 41%|████▏     | 42303488/102502400 [00:02<00:03, 15933010.85it/s]\u001b[A\n",
      " 43%|████▎     | 44138496/102502400 [00:02<00:03, 16025187.44it/s]\u001b[A\n",
      " 45%|████▍     | 45973504/102502400 [00:02<00:03, 16050766.18it/s]\u001b[A\n",
      " 47%|████▋     | 47726592/102502400 [00:02<00:03, 16467183.22it/s]\u001b[A\n",
      " 48%|████▊     | 49381376/102502400 [00:03<00:03, 15923769.59it/s]\u001b[A\n",
      " 50%|████▉     | 51036160/102502400 [00:03<00:03, 16101882.29it/s]\u001b[A\n",
      " 52%|█████▏    | 52789248/102502400 [00:03<00:03, 15973809.78it/s]\u001b[A\n",
      " 53%|█████▎    | 54624256/102502400 [00:03<00:02, 16087316.94it/s]\u001b[A\n",
      " 55%|█████▌    | 56459264/102502400 [00:03<00:02, 16150230.85it/s]\u001b[A\n",
      " 57%|█████▋    | 58294272/102502400 [00:03<00:02, 16215670.69it/s]\u001b[A\n",
      " 59%|█████▊    | 60104704/102502400 [00:03<00:02, 16738617.09it/s]\u001b[A\n",
      " 60%|██████    | 61784064/102502400 [00:03<00:02, 16177272.84it/s]\u001b[A\n",
      " 62%|██████▏   | 63537152/102502400 [00:03<00:02, 15978617.18it/s]\u001b[A\n",
      " 64%|██████▍   | 65372160/102502400 [00:04<00:02, 16082872.03it/s]\u001b[A\n",
      " 65%|██████▌   | 66985984/102502400 [00:04<00:02, 16058140.75it/s]\u001b[A\n",
      " 67%|██████▋   | 68780032/102502400 [00:04<00:02, 16021391.11it/s]\u001b[A\n",
      " 69%|██████▉   | 70615040/102502400 [00:04<00:01, 16138796.02it/s]\u001b[A\n",
      " 71%|███████   | 72450048/102502400 [00:04<00:01, 16212741.25it/s]\u001b[A\n",
      " 72%|███████▏  | 74285056/102502400 [00:04<00:01, 16276887.99it/s]\u001b[A\n",
      " 74%|███████▍  | 75988992/102502400 [00:04<00:01, 16296530.90it/s]\u001b[A\n",
      " 76%|███████▌  | 77774848/102502400 [00:04<00:01, 16733918.62it/s]\u001b[A\n",
      " 78%|███████▊  | 79454208/102502400 [00:04<00:01, 16296465.36it/s]\u001b[A\n",
      " 79%|███████▉  | 81231872/102502400 [00:05<00:01, 16190763.36it/s]\u001b[A\n",
      " 81%|████████  | 83066880/102502400 [00:05<00:01, 16213505.93it/s]\u001b[A\n",
      " 83%|████████▎ | 84697088/102502400 [00:05<00:01, 16210942.84it/s]\u001b[A\n",
      " 84%|████████▍ | 86376448/102502400 [00:05<00:00, 16378849.19it/s]\u001b[A\n",
      " 86%|████████▌ | 88047616/102502400 [00:05<00:00, 15860709.71it/s]\u001b[A\n",
      " 88%|████████▊ | 89882624/102502400 [00:05<00:00, 15955303.51it/s]\u001b[A\n",
      " 89%|████████▉ | 91717632/102502400 [00:05<00:00, 16048603.01it/s]\u001b[A\n",
      " 91%|█████████▏| 93552640/102502400 [00:05<00:00, 16139056.16it/s]\u001b[A\n",
      " 93%|█████████▎| 95223808/102502400 [00:05<00:00, 16306252.23it/s]\u001b[A\n",
      " 95%|█████████▍| 96960512/102502400 [00:06<00:00, 16092390.49it/s]\u001b[A\n",
      " 96%|█████████▋| 98795520/102502400 [00:06<00:00, 16113682.56it/s]\u001b[A\n",
      " 98%|█████████▊| 100515840/102502400 [00:06<00:00, 16421408.78it/s]\u001b[A\n",
      "100%|█████████▉| 102203392/102502400 [00:06<00:00, 15950564.05it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:06<00:00, 16046546.94it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64     # batch size\n",
    "vocab_threshold = 5 # minimum word count threshold\n",
    "vocab_from_file = False    # if True, load existing vocab file\n",
    "embed_size = 256         # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log_3.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr = 0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 4.1339, Perplexity: 62.4208\n",
      "Epoch [1/3], Step [200/6471], Loss: 4.0982, Perplexity: 60.2309\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.1890, Perplexity: 24.26489\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.4246, Perplexity: 30.71023\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.1045, Perplexity: 22.2980\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.1270, Perplexity: 22.80511\n",
      "Epoch [1/3], Step [700/6471], Loss: 3.5389, Perplexity: 34.4307\n",
      "Epoch [1/3], Step [800/6471], Loss: 3.1761, Perplexity: 23.9538\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.9703, Perplexity: 19.4978\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.9527, Perplexity: 19.1573\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.8001, Perplexity: 16.4470\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.7783, Perplexity: 16.0923\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.8065, Perplexity: 16.5519\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.6008, Perplexity: 13.4739\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.5046, Perplexity: 12.2382\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.7049, Perplexity: 14.9529\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.9302, Perplexity: 18.7312\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.5217, Perplexity: 12.4498\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.2704, Perplexity: 9.683537\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.3883, Perplexity: 10.8944\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.2656, Perplexity: 9.63720\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.7473, Perplexity: 15.6007\n",
      "Epoch [1/3], Step [2300/6471], Loss: 3.0947, Perplexity: 22.0801\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.4429, Perplexity: 11.5068\n",
      "Epoch [1/3], Step [2500/6471], Loss: 3.3296, Perplexity: 27.9279\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.3449, Perplexity: 10.4324\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.5007, Perplexity: 12.1906\n",
      "Epoch [1/3], Step [2900/6471], Loss: 3.3117, Perplexity: 27.4310\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.1650, Perplexity: 8.71433\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.2285, Perplexity: 9.28624\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.7508, Perplexity: 15.6547\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.0860, Perplexity: 8.05231\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.2435, Perplexity: 9.42603\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.4081, Perplexity: 11.1133\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.1936, Perplexity: 8.96744\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.1851, Perplexity: 8.89182\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.2611, Perplexity: 9.59359\n",
      "Epoch [1/3], Step [3900/6471], Loss: 3.2986, Perplexity: 27.0757\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.2774, Perplexity: 9.75149\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.5773, Perplexity: 13.1621\n",
      "Epoch [1/3], Step [4200/6471], Loss: 2.0025, Perplexity: 7.40730\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.4084, Perplexity: 11.1166\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.1991, Perplexity: 9.01690\n",
      "Epoch [1/3], Step [4500/6471], Loss: 3.3276, Perplexity: 27.8719\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.1373, Perplexity: 8.47612\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.1211, Perplexity: 8.34059\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.5726, Perplexity: 13.1003\n",
      "Epoch [1/3], Step [4900/6471], Loss: 2.2076, Perplexity: 9.09429\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.4665, Perplexity: 11.7815\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.4581, Perplexity: 11.6821\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.2081, Perplexity: 9.09876\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.1714, Perplexity: 8.77090\n",
      "Epoch [1/3], Step [5400/6471], Loss: 1.9957, Perplexity: 7.35776\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.4189, Perplexity: 11.2336\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.2695, Perplexity: 9.67493\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.0816, Perplexity: 8.01722\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.1659, Perplexity: 8.722236\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.2606, Perplexity: 9.58880\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.3886, Perplexity: 10.8980\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.3275, Perplexity: 10.2528\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.4584, Perplexity: 11.6859\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.1087, Perplexity: 8.23723\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.2067, Perplexity: 9.08605\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.7489, Perplexity: 15.62497\n",
      "Epoch [2/3], Step [200/6471], Loss: 2.3155, Perplexity: 10.1300\n",
      "Epoch [2/3], Step [300/6471], Loss: 2.1596, Perplexity: 8.66761\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.0276, Perplexity: 7.59566\n",
      "Epoch [2/3], Step [500/6471], Loss: 1.9231, Perplexity: 6.84183\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.3882, Perplexity: 10.8934\n",
      "Epoch [2/3], Step [700/6471], Loss: 1.8682, Perplexity: 6.47686\n",
      "Epoch [2/3], Step [800/6471], Loss: 2.1941, Perplexity: 8.97162\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.3180, Perplexity: 10.1552\n",
      "Epoch [2/3], Step [1000/6471], Loss: 2.2197, Perplexity: 9.2050\n",
      "Epoch [2/3], Step [1100/6471], Loss: 2.0272, Perplexity: 7.59266\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.0378, Perplexity: 7.67341\n",
      "Epoch [2/3], Step [1300/6471], Loss: 2.7071, Perplexity: 14.9862\n",
      "Epoch [2/3], Step [1400/6471], Loss: 2.0791, Perplexity: 7.99724\n",
      "Epoch [2/3], Step [1500/6471], Loss: 1.9764, Perplexity: 7.21651\n",
      "Epoch [2/3], Step [1600/6471], Loss: 2.0379, Perplexity: 7.67467\n",
      "Epoch [2/3], Step [1700/6471], Loss: 1.9182, Perplexity: 6.80895\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.0856, Perplexity: 8.04974\n",
      "Epoch [2/3], Step [1900/6471], Loss: 2.0990, Perplexity: 8.15779\n",
      "Epoch [2/3], Step [2000/6471], Loss: 2.2415, Perplexity: 9.40703\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.1155, Perplexity: 8.29350\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.1884, Perplexity: 8.92138\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.2511, Perplexity: 9.49826\n",
      "Epoch [2/3], Step [2400/6471], Loss: 1.9261, Perplexity: 6.86284\n",
      "Epoch [2/3], Step [2500/6471], Loss: 2.1030, Perplexity: 8.191164\n",
      "Epoch [2/3], Step [2600/6471], Loss: 2.0979, Perplexity: 8.14930\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.1065, Perplexity: 8.21978\n",
      "Epoch [2/3], Step [2800/6471], Loss: 1.9845, Perplexity: 7.27535\n",
      "Epoch [2/3], Step [2900/6471], Loss: 2.4348, Perplexity: 11.4134\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.0315, Perplexity: 7.62585\n",
      "Epoch [2/3], Step [3100/6471], Loss: 1.8653, Perplexity: 6.45789\n",
      "Epoch [2/3], Step [3200/6471], Loss: 1.8724, Perplexity: 6.50391\n",
      "Epoch [2/3], Step [3300/6471], Loss: 1.9889, Perplexity: 7.30768\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.0545, Perplexity: 7.80261\n",
      "Epoch [2/3], Step [3500/6471], Loss: 2.4070, Perplexity: 11.1009\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.1142, Perplexity: 8.28321\n",
      "Epoch [2/3], Step [3700/6471], Loss: 2.2221, Perplexity: 9.22708\n",
      "Epoch [2/3], Step [3800/6471], Loss: 1.9956, Perplexity: 7.35655\n",
      "Epoch [2/3], Step [3900/6471], Loss: 2.4421, Perplexity: 11.4977\n",
      "Epoch [2/3], Step [4000/6471], Loss: 1.9415, Perplexity: 6.96925\n",
      "Epoch [2/3], Step [4100/6471], Loss: 1.9953, Perplexity: 7.35417\n",
      "Epoch [2/3], Step [4200/6471], Loss: 1.9444, Perplexity: 6.98934\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.8126, Perplexity: 16.6538\n",
      "Epoch [2/3], Step [4400/6471], Loss: 2.0872, Perplexity: 8.06244\n",
      "Epoch [2/3], Step [4500/6471], Loss: 2.4174, Perplexity: 11.2169\n",
      "Epoch [2/3], Step [4600/6471], Loss: 1.9933, Perplexity: 7.33948\n",
      "Epoch [2/3], Step [4700/6471], Loss: 2.0496, Perplexity: 7.76492\n",
      "Epoch [2/3], Step [4800/6471], Loss: 1.9524, Perplexity: 7.04577\n",
      "Epoch [2/3], Step [4900/6471], Loss: 2.0235, Perplexity: 7.56482\n",
      "Epoch [2/3], Step [5000/6471], Loss: 1.8963, Perplexity: 6.66109\n",
      "Epoch [2/3], Step [5100/6471], Loss: 1.9134, Perplexity: 6.77631\n",
      "Epoch [2/3], Step [5200/6471], Loss: 2.1380, Perplexity: 8.48226\n",
      "Epoch [2/3], Step [5300/6471], Loss: 2.2000, Perplexity: 9.02513\n",
      "Epoch [2/3], Step [5400/6471], Loss: 1.9843, Perplexity: 7.27418\n",
      "Epoch [2/3], Step [5500/6471], Loss: 2.3241, Perplexity: 10.2174\n",
      "Epoch [2/3], Step [5600/6471], Loss: 2.2490, Perplexity: 9.47789\n",
      "Epoch [2/3], Step [5700/6471], Loss: 1.9186, Perplexity: 6.81145\n",
      "Epoch [2/3], Step [5800/6471], Loss: 2.0275, Perplexity: 7.59543\n",
      "Epoch [2/3], Step [5900/6471], Loss: 2.1278, Perplexity: 8.39646\n",
      "Epoch [2/3], Step [6000/6471], Loss: 2.3889, Perplexity: 10.90173\n",
      "Epoch [2/3], Step [6100/6471], Loss: 1.9028, Perplexity: 6.70485\n",
      "Epoch [2/3], Step [6200/6471], Loss: 2.1056, Perplexity: 8.21229\n",
      "Epoch [2/3], Step [6300/6471], Loss: 1.8685, Perplexity: 6.47860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Step [6400/6471], Loss: 2.0556, Perplexity: 7.81155\n",
      "Epoch [3/3], Step [100/6471], Loss: 1.9555, Perplexity: 7.067508\n",
      "Epoch [3/3], Step [200/6471], Loss: 1.9767, Perplexity: 7.21907\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.0083, Perplexity: 7.45107\n",
      "Epoch [3/3], Step [400/6471], Loss: 2.0167, Perplexity: 7.51385\n",
      "Epoch [3/3], Step [500/6471], Loss: 2.1220, Perplexity: 8.34754\n",
      "Epoch [3/3], Step [600/6471], Loss: 2.1269, Perplexity: 8.38853\n",
      "Epoch [3/3], Step [700/6471], Loss: 2.1314, Perplexity: 8.42660\n",
      "Epoch [3/3], Step [800/6471], Loss: 1.9425, Perplexity: 6.97607\n",
      "Epoch [3/3], Step [900/6471], Loss: 1.8837, Perplexity: 6.57762\n",
      "Epoch [3/3], Step [1000/6471], Loss: 1.9560, Perplexity: 7.0711\n",
      "Epoch [3/3], Step [1100/6471], Loss: 1.7577, Perplexity: 5.79924\n",
      "Epoch [3/3], Step [1200/6471], Loss: 1.9487, Perplexity: 7.01936\n",
      "Epoch [3/3], Step [1300/6471], Loss: 1.8334, Perplexity: 6.25524\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.0607, Perplexity: 7.85153\n",
      "Epoch [3/3], Step [1500/6471], Loss: 2.3379, Perplexity: 10.3591\n",
      "Epoch [3/3], Step [1600/6471], Loss: 1.8383, Perplexity: 6.28585\n",
      "Epoch [3/3], Step [1700/6471], Loss: 2.0449, Perplexity: 7.72829\n",
      "Epoch [3/3], Step [1800/6471], Loss: 1.9211, Perplexity: 6.82823\n",
      "Epoch [3/3], Step [1900/6471], Loss: 1.9234, Perplexity: 6.84400\n",
      "Epoch [3/3], Step [2000/6471], Loss: 2.7109, Perplexity: 15.0427\n",
      "Epoch [3/3], Step [2100/6471], Loss: 2.1086, Perplexity: 8.23641\n",
      "Epoch [3/3], Step [2200/6471], Loss: 1.9250, Perplexity: 6.85534\n",
      "Epoch [3/3], Step [2300/6471], Loss: 2.1126, Perplexity: 8.26971\n",
      "Epoch [3/3], Step [2400/6471], Loss: 1.9543, Perplexity: 7.05915\n",
      "Epoch [3/3], Step [2500/6471], Loss: 1.9719, Perplexity: 7.18427\n",
      "Epoch [3/3], Step [2600/6471], Loss: 1.8494, Perplexity: 6.35599\n",
      "Epoch [3/3], Step [2700/6471], Loss: 1.9970, Perplexity: 7.36724\n",
      "Epoch [3/3], Step [2800/6471], Loss: 1.9823, Perplexity: 7.25942\n",
      "Epoch [3/3], Step [2900/6471], Loss: 1.8554, Perplexity: 6.39414\n",
      "Epoch [3/3], Step [3000/6471], Loss: 2.0503, Perplexity: 7.77031\n",
      "Epoch [3/3], Step [3100/6471], Loss: 1.7844, Perplexity: 5.95633\n",
      "Epoch [3/3], Step [3200/6471], Loss: 1.9286, Perplexity: 6.88011\n",
      "Epoch [3/3], Step [3300/6471], Loss: 1.7997, Perplexity: 6.04777\n",
      "Epoch [3/3], Step [3400/6471], Loss: 1.9898, Perplexity: 7.31393\n",
      "Epoch [3/3], Step [3500/6471], Loss: 2.3982, Perplexity: 11.0034\n",
      "Epoch [3/3], Step [3600/6471], Loss: 2.0973, Perplexity: 8.14400\n",
      "Epoch [3/3], Step [3700/6471], Loss: 2.0299, Perplexity: 7.61349\n",
      "Epoch [3/3], Step [3800/6471], Loss: 1.9031, Perplexity: 6.70657\n",
      "Epoch [3/3], Step [3900/6471], Loss: 2.0495, Perplexity: 7.76372\n",
      "Epoch [3/3], Step [4000/6471], Loss: 1.9429, Perplexity: 6.97865\n",
      "Epoch [3/3], Step [4100/6471], Loss: 2.0032, Perplexity: 7.41273\n",
      "Epoch [3/3], Step [4200/6471], Loss: 1.8837, Perplexity: 6.57759\n",
      "Epoch [3/3], Step [4300/6471], Loss: 1.9129, Perplexity: 6.77290\n",
      "Epoch [3/3], Step [4400/6471], Loss: 1.9207, Perplexity: 6.82583\n",
      "Epoch [3/3], Step [4500/6471], Loss: 1.7892, Perplexity: 5.98491\n",
      "Epoch [3/3], Step [4600/6471], Loss: 2.1410, Perplexity: 8.50798\n",
      "Epoch [3/3], Step [4700/6471], Loss: 2.0537, Perplexity: 7.79634\n",
      "Epoch [3/3], Step [4800/6471], Loss: 1.8131, Perplexity: 6.12965\n",
      "Epoch [3/3], Step [4900/6471], Loss: 2.6165, Perplexity: 13.6872\n",
      "Epoch [3/3], Step [5000/6471], Loss: 1.7904, Perplexity: 5.99208\n",
      "Epoch [3/3], Step [5100/6471], Loss: 1.9457, Perplexity: 6.99877\n",
      "Epoch [3/3], Step [5200/6471], Loss: 2.2788, Perplexity: 9.76502\n",
      "Epoch [3/3], Step [5300/6471], Loss: 1.9569, Perplexity: 7.07724\n",
      "Epoch [3/3], Step [5400/6471], Loss: 2.1377, Perplexity: 8.47988\n",
      "Epoch [3/3], Step [5500/6471], Loss: 1.8294, Perplexity: 6.23037\n",
      "Epoch [3/3], Step [5600/6471], Loss: 1.8506, Perplexity: 6.36386\n",
      "Epoch [3/3], Step [5700/6471], Loss: 1.9083, Perplexity: 6.74154\n",
      "Epoch [3/3], Step [5800/6471], Loss: 2.0108, Perplexity: 7.46924\n",
      "Epoch [3/3], Step [5900/6471], Loss: 1.8892, Perplexity: 6.61390\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.9226, Perplexity: 6.83850\n",
      "Epoch [3/3], Step [6100/6471], Loss: 1.8030, Perplexity: 6.06812\n",
      "Epoch [3/3], Step [6200/6471], Loss: 1.7648, Perplexity: 5.84068\n",
      "Epoch [3/3], Step [6300/6471], Loss: 1.9445, Perplexity: 6.99042\n",
      "Epoch [3/3], Step [6400/6471], Loss: 1.9887, Perplexity: 7.30594\n",
      "Epoch [3/3], Step [6471/6471], Loss: 1.9336, Perplexity: 6.91442"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-3-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-3-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
